{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Group_Equivariant_ResNet44_full_implementation.ipynb","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMB1IsV7GrdPz5cY7CpRvx6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"vJZ_fwm8qPlB","colab_type":"text"},"source":["#**I**. Installing package *Groupy* + mount Google Drive"]},{"cell_type":"code","metadata":{"id":"9SW2VnsZrpFv","colab_type":"code","colab":{}},"source":["#connecting with drive and computer\n","import sys\n","from google.colab import drive\n","import importlib.util\n","\n","# Mounting Google Drive \n","drive.mount('/content/gdrive')\n","\n","!pip install nose\n","!pip install chainer\n","\n","%cd /content/gdrive/My Drive/Deep Learning/Reproduction project\n","! git clone https://github.com/adambielski/GrouPy.git\n","\n","%cd /content/gdrive/My Drive/Deep Learning/Reproduction project/GrouPy\n","! python setup.py install\n","\n","!nosetests -v"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ehWYpz79p7zY","colab_type":"text"},"source":["#**II**. Import packages"]},{"cell_type":"code","metadata":{"id":"-4qEAixhrXIv","colab_type":"code","colab":{}},"source":["#pytorch\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchsummary import summary\n","from torch.autograd import Variable\n","\n","#groupy import\n","from groupy.gconv.pytorch_gconv.splitgconv2d import P4ConvZ2, P4ConvP4, P4MConvZ2, P4MConvP4M\n","\n","#general\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import time\n","import math\n","\n","#some extra\n","from functools import partial\n","from dataclasses import dataclass\n","from collections import OrderedDict"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7gSyfUlEqu0O","colab_type":"text"},"source":["#**III**. Building the model(s): a Pytorch implementation\n","\n"]},{"cell_type":"code","metadata":{"id":"auJDal9zvq0G","colab_type":"code","colab":{}},"source":["'''\n","Here the ResNet class is created. It does so specifically for p4m. It needs some\n","trivial adaptation to work for the conventional and other group form (p4) as well:\n","BatchNorm3d should be replaced if a conventional residual network is wanted.\n","Secondly, all convolutions should be replaced by either Conv2D or P4ConvP4/Z2\n","depending on the type of network you want to create. There will come a version\n","in which this can be done automatically, but it is not this day.\n","'''\n","\n","# ------------------------ CLASS RESIDUAL BLOCK --------------------------------\n","class ResidualBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.in_channels, self.out_channels =  in_channels, out_channels\n","        self.blocks   = nn.Identity() #initialize block as identity\n","        self.shortcut = nn.Identity() #initialize skip as identity\n","    \n","    def forward(self, x):\n","        #shortcut\n","        residual = x\n","        if self.should_apply_shortcut: residual = self.shortcut(x)\n","        x = self.blocks(x)\n","\n","        #combination\n","        x += residual\n","        x = F.relu(x)\n","        return x\n","    \n","    @property\n","    def should_apply_shortcut(self):\n","        return self.in_channels != self.out_channels\n","\n","\n","# ----------------------- CLASS RESNET RESIDUAL BLOCK --------------------------\n","class ResNetResidualBlock(ResidualBlock):\n","    def __init__(self, in_channels, out_channels, expansion=1, downsampling=1, \n","                 conv=P4MConvP4M, *args, **kwargs):\n","        super().__init__(in_channels, out_channels)\n","        self.expansion, self.downsampling, self.conv = expansion, downsampling, conv\n","\n","        self.shortcut = nn.Sequential(OrderedDict({\n","            'conv' : P4MConvP4M(self.in_channels, \n","                                self.expanded_channels, kernel_size=1,\n","                                stride=self.downsampling, bias=False),\n","            'bn'   : nn.BatchNorm3d(self.expanded_channels)\n","            \n","        })) if self.should_apply_shortcut else None \n","\n","        \n","    @property\n","    def expanded_channels(self):\n","        return self.out_channels * self.expansion\n","    \n","    @property\n","    def should_apply_shortcut(self):\n","        return self.in_channels != self.expanded_channels\n","\n","\n","\n","# --------------------- PRE CONVOLUTION SEQUENTIAL -----------------------------\n","def bn_conv(in_channels, out_channels, conv, activation = nn.ReLU, *args, **kwargs):\n","    return nn.Sequential(OrderedDict({'conv': conv(in_channels, out_channels, \n","                                                   kernel_size = 3, padding = 1, \n","                                                   *args, **kwargs),\n","                                      'bn': nn.BatchNorm3d(out_channels)}))\n","    \n","\n","# ------------------------- CLASS BASIC BLOCK ----------------------------------\n","class ResNetBasicBlock(ResNetResidualBlock):\n","    expansion = 1\n","    def __init__(self, in_channels, out_channels, *args, **kwargs):\n","        super().__init__(in_channels, out_channels, *args, **kwargs)\n","        self.blocks = nn.Sequential(\n","            bn_conv(self.in_channels, self.out_channels, conv=self.conv, \n","                     bias=False, stride=self.downsampling),\n","            nn.ReLU(),\n","            bn_conv(self.out_channels, self.expanded_channels, \n","                     conv=self.conv, bias=False),\n","        )\n","\n","\n","# ------------------------- CLASS RESNET LAYER ---------------------------------\n","class ResNetLayer(nn.Module):\n","    def __init__(self, in_channels, out_channels, block=ResNetBasicBlock, n=1, *args, **kwargs):\n","        super().__init__()\n","        # 'We perform downsampling directly by convolutional layers that have a stride of 2.'\n","        downsampling = 2 if in_channels != out_channels else 1\n","        \n","        #first introduce block(... )\n","        self.blocks = nn.Sequential(\n","            block(in_channels , out_channels, *args, **kwargs, downsampling=downsampling),\n","            # in the next the n-1 blocks are subsequently stacked (_ underscore means\n","            # that the do_something will be executed the prescribed amount of times\n","            *[block(out_channels * block.expansion, \n","                    out_channels, downsampling=1, *args, **kwargs) for _ in range(n - 1)]\n","        )\n","\n","    def forward(self, x):\n","        x = self.blocks(x)\n","        return x\n","\n","\n","# ------------------------- CLASS RESNET ENCODER -------------------------------\n","class ResNetEncoder(nn.Module): \n","    def __init__(self, in_channels=3, blocks_sizes=[11, 23, 45], depths=[7,7,7], \n","                 activation=nn.ReLU, block=ResNetBasicBlock, *args,**kwargs):\n","        super().__init__()\n","\n","        self.blocks_sizes = blocks_sizes\n","        \n","        self.initconv = nn.Sequential(OrderedDict({\n","            'conv'    : P4MConvZ2(in_channels, self.blocks_sizes[0], \n","                        kernel_size=7, stride = 1, padding=3, bias=False),\n","            'bn'      : nn.BatchNorm3d(self.blocks_sizes[0]),\n","            'act'     : activation()})\n","        )\n","        \n","        self.in_out_block_sizes = list(zip(blocks_sizes, blocks_sizes[1:]))\n","        self.blocks = nn.ModuleList([ \n","            ResNetLayer(blocks_sizes[0], blocks_sizes[0], n=depths[0], activation=activation, \n","                        block=block,  *args, **kwargs),\n","            *[ResNetLayer(in_channels * block.expansion, \n","                          out_channels, n=n, activation=activation, \n","                          block=block, *args, **kwargs) \n","              for (in_channels, out_channels), n in zip(self.in_out_block_sizes, depths[1:])]       \n","        ])\n","        \n","        \n","    def forward(self, x):\n","        x = self.initconv(x)\n","        for block in self.blocks:\n","            x = block(x)\n","        return x\n","\n","\n","# ------------------------- CLASS RESNET DECODER -------------------------------\n","class ResNetDecoder(nn.Module):\n","    \"\"\"\n","    This class represents the tail of the ResNet, also know as the decoder part. \n","    Average pooling is followed by a fully connected 1-hidden layer deep neural\n","    network.\n","    \"\"\"\n","    def __init__(self, in_features, n_classes, *args, **kwargs):\n","        super().__init__()\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.decoder = nn.Linear(in_features, n_classes)\n","\n","    def forward(self, x):\n","        x = self.avgpool(x)\n","        x = x.view(x.size(0), -1) #flatten\n","        x = self.decoder(x)\n","        return x\n","\n","\n","# ------------------------------ CLASS RESNET ----------------------------------\n","class ResNet(nn.Module):\n","    '''\n","    This class represents the full implementation of the residual network. This is\n","    the connection of the encoder (initial convolution and residual stages) \n","    followed by the decoder (fully connected network).\n","    '''\n","    def __init__(self, in_channels, n_classes, choice = 1, *args, **kwargs):\n","        super().__init__()\n","\n","        self.encoder = ResNetEncoder(in_channels, *args, **kwargs)\n","        self.decoder = ResNetDecoder(self.encoder.blocks[-1].blocks[-1].expanded_channels*8, n_classes)\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        xs = x.size()\n","        x = x.view(xs[0], xs[1]*xs[2], xs[3], xs[4])\n","        x = self.decoder(x)\n","        return x\n","\n","\n","# ----------------------------- DEFINE RESNET44 --------------------------------\n","# here, the model is created\n","def resnet44_P4M(in_channels, n_classes):\n","    return ResNet(in_channels, n_classes, block=ResNetBasicBlock, depths=[7, 7, 7])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zp18kEFJqlnw","colab_type":"text"},"source":["#**IV**. Loading a model"]},{"cell_type":"code","metadata":{"id":"3VB2cOhEskhC","colab_type":"code","colab":{}},"source":["'''\n","It is sometimes prefered to load a model or its checkpoint to either continue training\n","or evaluate some of its properties. This small piece of code can come in handy.\n","It assumes the models was earlier saved using _state_dict() which only saves the \n","values of the parameters instead of the model as a whole (it simply takes less \n","space and time this way). Therefor, first assign the the network to the model \n","and second load the values of its parameters using load_state_dict().\n","'''\n","#Loading model\n","name_model = input('Name model?') #input name of the model (how it is saved)\n","directory = '/content/gdrive/My Drive/Deep Learning/Reproduction project/Saved Networks/Preliminary/' #put your own directory here\n","path_model = directory + name_model + '.pth'\n","model = ResNet(3, 10, block=ResNetBasicBlock, depths=[7, 7, 7]) \n","result = model.load_state_dict(torch.load(path_model)) #check of alle weights zijn geladen\n","\n","#print results: if missing keys and unexpected keys are empty, the model has been loaded in splendid fashion\n","print('')\n","print('=== Weights loaded ===')\n","print('Missing keys:   ', result.missing_keys)\n","print('Unexpected keys:', result.unexpected_keys)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dICbFNel0aRy","colab_type":"text"},"source":["#**V**. Loading the data"]},{"cell_type":"code","metadata":{"id":"kXTWp7BB0iWM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"9f9ec281-cffc-4850-b6c1-24a5030f83ed","executionInfo":{"status":"ok","timestamp":1587408111635,"user_tz":-120,"elapsed":9294,"user":{"displayName":"Casper van Engelenburg","photoUrl":"","userId":"15574604206268867227"}}},"source":["'''\n","Here the data is loaded: training set and test set. \n","'''\n","\n","#Normalize a tensor image with mean and standard deviation. \n","transform_train = transforms.Compose([\n","    transforms.ToTensor(), #add other transformation if you like here\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","# Load training sets\n","batch_size  = 64\n","num_workers = 2\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=transform_train)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n","                                          shuffle=True, num_workers=num_workers)\n","\n","# Load test sets\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=transform_test)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n","                                         shuffle=False, num_workers=num_workers)\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PXvsM-yJrEJW","colab_type":"text"},"source":["#**VI**. Evaluation of the models"]},{"cell_type":"code","metadata":{"id":"3ia4oahszOj3","colab_type":"code","colab":{}},"source":["'''\n","The model is trained, evaluated and saved here. The function train_network() \n","does the job for you. It automatically saves the model and its train, test and \n","loss curves so far. Furthermore, during training you will get a live update \n","every epoch of the scores so far.\n","'''\n","\n","# ------------------------- TRAINING THE NETWORK -------------------------------\n","def train_network(net, train_loader, test_loader, device, title,\n","                  lr = 0.05, momentum = 0.9, gamma = 0.1, \n","                  n_epochs = 300, epoch_start = 0,\n","                  criterion = nn.CrossEntropyLoss().cuda()):\n","    \"\"\"\n","    Training and evaluation of a connected network which should be written\n","    in Pytorch fashion.\n","    \"\"\"\n","\n","    print('training on', device)\n","\n","    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n","\n","    #Create vectors with information on loss, training accuracy and test accuracy\n","    loss_curve   = np.zeros((n_epochs))\n","    train_curve  = np.zeros((n_epochs))\n","    test_curve   = np.zeros((n_epochs))\n","\n","    #vector with epochs\n","    epoch_vec = np.arange(epoch_start,n_epochs)\n","\n","    # ---------------------------- START TRAINING ------------------------------\n","    for epoch in epoch_vec:\n","\n","        net.train()\n","        n, start = 0, time.time()\n","\n","        train_l_sum   = torch.tensor([0.0], dtype=torch.float32, device=device)\n","        train_acc_sum = torch.tensor([0.0], dtype=torch.float32, device=device)\n","\n","        for i, data in enumerate(train_loader, 0):\n","\n","            inputs, labels = data\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = net(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","        \n","            with torch.no_grad():\n","                outputs = outputs.long()\n","                train_l_sum += loss.float()\n","                n += outputs.shape[0]\n","\n","        #update learning rate\n","        if epoch <= 300:\n","            if epoch % 50 == 49:\n","                lr *= gamma\n","                optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n","                print('We got ourselves a change in learning rate:')\n","                print('Epoch: '+ str(epoch))\n","                print('Learning rate changed to: ' + str(lr))\n","\n","        # ------------------- START VALIDATION and SAVING ----------------------\n","        loss_value = train_l_sum/n\n","\n","        stop1 = time.time()\n","        train_acc  = evaluate_accuracy(train_loader, net, device)\n","        stop2 = time.time()\n","        test_acc   = evaluate_accuracy(test_loader, net, device)\n","\n","        loss_curve[epoch]  = loss_value\n","        train_curve[epoch] = train_acc\n","        test_curve[epoch]  = test_acc\n","\n","        curves = np.array([loss_curve, train_curve, test_curve])\n","\n","        #print updated scores\n","        print('epoch %d [#]  |  loss %.4f [-]  |  train acc %.3f [-]  |  test acc %.3f [-]  |  time %.1f-%.1f-%.1f [s]'\\\n","        % (epoch + 1, loss_value, train_acc, test_acc, stop1-start, stop2-stop1, time.time()-stop2))\n","        \n","        #save every 5 epochs\n","        if epoch % 50 == 49:    # save every 10 epochs\n","            #model\n","            name_to_save = title + '__test=' + str(test_acc) + '%_train=' + str(train_acc) + '%_epoch=' + str(epoch+1)\n","            directory = '/content/gdrive/My Drive/Deep Learning/Reproduction project/Saved Networks/Preliminary/'\n","            path = '/content/gdrive/My Drive/Deep Learning/Reproduction project/Saved Networks/Preliminary/' + name_to_save + '.pth'\n","            torch.save(model.state_dict(), path)\n","            \n","            #learning curves\n","            path2 = directory + name_to_save + '_start:' + str(epoch_start)\n","            np.save(path2, curves) \n","      \n","    print('Finished Training')\n","\n","\n","\n","# ------------------------------ VALIDATION ------------------------------------\n","def evaluate_accuracy(data_iter, net, device=torch.device('cpu')):\n","    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n","    net.eval()  # Switch to evaluation mode for Dropout, BatchNorm etc layers.\n","    acc_sum, n = torch.tensor([0], dtype=torch.float32, device=device), 0\n","    for X, y in data_iter:\n","        # Copy the data to device.\n","        X, y = X.to(device), y.to(device)\n","        with torch.no_grad():\n","            y = y.long()\n","            acc_sum += torch.sum((torch.argmax(net(X), dim=1) == y))\n","            n += y.shape[0]\n","    return acc_sum.item()/n\n","\n","# ------------------------- IN THE HOPE FOR GPU --------------------------------\n","def try_gpu():\n","    \"\"\"If GPU is available, return torch.device as cuda:0; else return torch.device as cpu.\"\"\"\n","    if torch.cuda.is_available():\n","        device = torch.device('cuda:0')\n","    else:\n","        device = torch.device('cpu')\n","    return device\n","\n","\n","# ----------------------------------- MAIN -------------------------------------\n","\n","def main(): #in here we put everything we want to be runned over\n","    #get GPU\n","    device = try_gpu()\n","\n","    #define model\n","    model = resnet44_P4M(3,10)\n","    model.cuda()\n","\n","    #define the starting epoch, only non-zero if you start at a checkpoint\n","    epoch_start = 0\n","    \n","    #define batch size and titel of the model (for saving)\n","    bs = input('What is the batch size:')\n","    title = 'ResNet44Groupy10_P4M_bs:' + bs +'_SGD_every50epochs'\n","\n","    #train the network\n","    train_network(model, trainloader, testloader, device, title, n_epochs = 300, epoch_start = epoch_start)\n","\n","if __name__ == \"__main__\": \n","    main()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m7mc9eVQrNxO","colab_type":"text"},"source":["#**VII**. Extra: creating learning curves"]},{"cell_type":"code","metadata":{"id":"u6MMIsiV2acI","colab_type":"code","colab":{}},"source":["'''\n","Creates two plots for CIFAR10 and CIFAR10+ for all three networks. Please fill \n","in your own directory and paths where the curves of the networks can be found. \n","'''\n","\n","#------------------------------- LOADING DATA ----------------------------------\n","directory = '/content/gdrive/My Drive/Deep Learning/Reproduction project/Saved Networks/Preliminary/'\n","\n","#path names (N: conventional convolutions, P4 and P4M for group equivariant convolutions)\n","#10\n","path10_N    = directory + 'ResNet44Normal10_bs:128_SGD_every50epochs__test=0.8646%_train=1.0%_epoch=300_start:0.npy' \n","path10_P4   = directory + 'ResNet44Groupy10_bs:128_SGD_every50epochs__test=0.8509%_train=0.99722%_epoch=250_start:0.npy'\n","path10_P4M  = directory + 'ResNet44Groupy10_P4M_bs:64_SGD_every50epochs__test=0.909%_train=0.99998%_epoch=50_start:0.npy'\n","\n","#10+\n","path10p_N    = directory + 'ResNet44Normal_bs:64_SGD_every50epochs__test=0.9136%_train=0.9999%_epoch=300_start:0.npy'\n","path10p_P4   = directory + 'ResNet44Groupy_bs:64_SGD_every50epochs__test=0.9288%_train=0.9999%_epoch=300_start:0.npy'\n","path10p_P4M  = directory + 'ResNet44Groupy_P4M_bs:64_SGD_every50epochs__test=0.9191%_train=0.99998%_epoch=220_start:0.npy'\n","\n","#loading curves\n","curve10_N    = np.load(path10_N)\n","curve10_P4   = np.load(path10_P4)\n","curve10_P4M  = np.load(path10_P4M)\n","curve10p_N   = np.load(path10p_N)\n","curve10p_P4  = np.load(path10p_P4)\n","curve10p_P4M = np.load(path10p_P4M)\n","\n","#extract training, test and loss curves\n","#1st dimension: 10 or 10+ | second dimension: normal, P4 or P4M | third: data\n","train_curve = np.array([[curve10_N[1,:], curve10_P4[1,:], curve10_P4M[1,:]], \n","                        [curve10p_N[1,:], curve10p_P4[1,:], curve10p_P4M[1,:]]])\n","test_curve  = np.array([[curve10_N[2,:], curve10_P4[2,:], curve10_P4M[2,:]], \n","                        [curve10p_N[2,:], curve10p_P4[2,:], curve10p_P4M[2,:]]])\n","\n","best_score = test_curve.max(axis = 2)\n","best_score = 100*(1 - best_score)\n","\n","#---------------------------- PLOTTING THE RESULT ------------------------------\n","def plot_setting(fontfamily = 'Tahoma', \n","                 weight = 'normal', \n","                 fontsize = 16, \n","                 figsize = [14, 14]):\n","  \n","    plt.rcParams['figure.figsize'] = figsize\n","\n","    font = {'size'   : fontsize,\n","            'family' : fontfamily,\n","            'weight' : weight}\n","\n","    plt.rc('font', **font)\n","    plt.grid()\n","\n","def plot_learning_curves_all(train_curve, test_curve, batch_size, best_score, stop = [100, 200]):\n","    plot_setting(fontfamily = 'sans-serif')\n","\n","    #create legends for convolution types\n","    legends = ['Z2', 'P4', 'P4M']\n","\n","    #CIFAR10\n","    plt.figure(num=1)\n","\n","    for i, legend in enumerate(legends):\n","        plt.plot(100*(1-train_curve[0, i,:stop[0]]),'--', label = 'Training | ' \n","                 + legend + ' | batch size= ' + batch_size)\n","        plt.plot(100*(1-test_curve[0, i,:stop[0]]),'-', linewidth = 2,  label = 'Testing  | ' \n","                 + legend + ' | batch size= ' + batch_size + ' | best score=' \n","                 + str(best_score[0, i]) + '%')\n","    plt.xlabel('Epoch [#]')\n","    plt.ylabel('Error [%]')\n","    plt.legend()\n","    plt.title('Learning curves: CIFAR 10')\n","\n","\n","    #CIFAR10\n","    plt.figure(num=2)\n","\n","    for i, legend in enumerate(legends):\n","        plt.plot(100*(1-train_curve[1, i,:stop[1]]),'--', label = 'Training | ' \n","                 + legend + ' | batch size= ' + batch_size)\n","        plt.plot(100*(1-test_curve[1, i,:stop[1]]),'-', linewidth = 2,  \n","                 label = 'Testing  | ' + legend + ' | batch size= ' \n","                 + batch_size + ' | best score=' + str(best_score[1, i]) + '%')\n","    plt.xlabel('Epoch [#]')\n","    plt.ylabel('Error [%]')\n","    plt.legend()\n","    plt.title('Learning curves: CIFAR 10+')\n","\n","plot_learning_curves_all(train_curve, test_curve, '64', best_score.round(decimals = 2), stop = [200, 200])"],"execution_count":0,"outputs":[]}]}