{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Group_ResNet44_Casper.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flWPQTtVRfH6",
        "colab_type": "text"
      },
      "source": [
        "#Import + mount Google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z19hw6lyRXzo",
        "colab_type": "code",
        "outputId": "688b4e3d-1ae1-43a5-988d-cda7d9807889",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "\n",
        "import math\n",
        "\n",
        "from functools import partial\n",
        "from dataclasses import dataclass\n",
        "from collections import OrderedDict\n",
        "\n",
        "import sys\n",
        "from google.colab import drive\n",
        "import importlib.util\n",
        "\n",
        "# Mounting Google Drive \n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "\n",
        "#use GPU is available\n",
        "use_gpu = torch.cuda.is_available()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Berj1iihfBXc",
        "colab_type": "text"
      },
      "source": [
        "#Groupy loading and installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_1TY8ExfQSs",
        "colab_type": "code",
        "outputId": "3b2778c0-5185-4c0a-d005-b090fb514893",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install nose\n",
        "!pip install chainer\n",
        "\n",
        "%cd /content/gdrive/My Drive/Deep Learning/Reproduction project\n",
        "! git clone https://github.com/adambielski/GrouPy.git\n",
        "\n",
        "%cd /content/gdrive/My Drive/Deep Learning/Reproduction project/GrouPy\n",
        "! python setup.py install\n",
        "\n",
        "!nosetests -v\n",
        "\n",
        "from groupy.gconv.pytorch_gconv.splitgconv2d import P4ConvZ2, P4ConvP4, P4MConvZ2, P4MConvP4M"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nose\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\r\u001b[K     |██▏                             | 10kB 18.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 20kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 30kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 40kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 51kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 61kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 71kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 81kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 92kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 102kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 112kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 122kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 133kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 143kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 153kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 163kB 6.5MB/s \n",
            "\u001b[?25hInstalling collected packages: nose\n",
            "Successfully installed nose-1.3.7\n",
            "Requirement already satisfied: chainer in /usr/local/lib/python3.6/dist-packages (6.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from chainer) (3.0.12)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from chainer) (1.12.0)\n",
            "Requirement already satisfied: typing<=3.6.6 in /usr/local/lib/python3.6/dist-packages (from chainer) (3.6.6)\n",
            "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from chainer) (3.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from chainer) (46.1.3)\n",
            "Requirement already satisfied: typing-extensions<=3.6.6 in /usr/local/lib/python3.6/dist-packages (from chainer) (3.6.6)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from chainer) (1.18.2)\n",
            "/content/gdrive/My Drive/Deep Learning/Reproduction project\n",
            "fatal: destination path 'GrouPy' already exists and is not an empty directory.\n",
            "/content/gdrive/My Drive/Deep Learning/Reproduction project/GrouPy\n",
            "running install\n",
            "running build\n",
            "running build_py\n",
            "running install_lib\n",
            "creating /usr/local/lib/python3.6/dist-packages/groupy\n",
            "copying build/lib/groupy/__init__.py -> /usr/local/lib/python3.6/dist-packages/groupy\n",
            "creating /usr/local/lib/python3.6/dist-packages/groupy/garray\n",
            "copying build/lib/groupy/garray/test_garray.py -> /usr/local/lib/python3.6/dist-packages/groupy/garray\n",
            "copying build/lib/groupy/garray/garray.py -> /usr/local/lib/python3.6/dist-packages/groupy/garray\n",
            "copying build/lib/groupy/garray/__init__.py -> /usr/local/lib/python3.6/dist-packages/groupy/garray\n",
            "copying build/lib/groupy/garray/Z2_array.py -> /usr/local/lib/python3.6/dist-packages/groupy/garray\n",
            "copying build/lib/groupy/garray/finitegroup.py -> /usr/local/lib/python3.6/dist-packages/groupy/garray\n",
            "copying build/lib/groupy/garray/matrix_garray.py -> /usr/local/lib/python3.6/dist-packages/groupy/garray\n",
            "copying build/lib/groupy/garray/C4_array.py -> /usr/local/lib/python3.6/dist-packages/groupy/garray\n",
            "copying build/lib/groupy/garray/D4_array.py -> /usr/local/lib/python3.6/dist-packages/groupy/garray\n",
            "copying build/lib/groupy/garray/p4m_array.py -> /usr/local/lib/python3.6/dist-packages/groupy/garray\n",
            "copying build/lib/groupy/garray/p4_array.py -> /usr/local/lib/python3.6/dist-packages/groupy/garray\n",
            "creating /usr/local/lib/python3.6/dist-packages/groupy/gconv\n",
            "copying build/lib/groupy/gconv/__init__.py -> /usr/local/lib/python3.6/dist-packages/groupy/gconv\n",
            "copying build/lib/groupy/gconv/make_gconv_indices.py -> /usr/local/lib/python3.6/dist-packages/groupy/gconv\n",
            "creating /usr/local/lib/python3.6/dist-packages/groupy/gconv/chainer_gconv\n",
            "copying build/lib/groupy/gconv/chainer_gconv/transform_filter.py -> /usr/local/lib/python3.6/dist-packages/groupy/gconv/chainer_gconv\n",
            "copying build/lib/groupy/gconv/chainer_gconv/p4_conv.py -> /usr/local/lib/python3.6/dist-packages/groupy/gconv/chainer_gconv\n",
            "copying build/lib/groupy/gconv/chainer_gconv/test_gconv.py -> /usr/local/lib/python3.6/dist-packages/groupy/gconv/chainer_gconv\n",
            "copying build/lib/groupy/gconv/chainer_gconv/__init__.py -> /usr/local/lib/python3.6/dist-packages/groupy/gconv/chainer_gconv\n",
            "copying build/lib/groupy/gconv/chainer_gconv/test_transform_filter.py -> /usr/local/lib/python3.6/dist-packages/groupy/gconv/chainer_gconv\n",
            "copying build/lib/groupy/gconv/chainer_gconv/p4m_conv.py -> /usr/local/lib/python3.6/dist-packages/groupy/gconv/chainer_gconv\n",
            "copying build/lib/groupy/gconv/chainer_gconv/splitgconv2d.py -> /usr/local/lib/python3.6/dist-packages/groupy/gconv/chainer_gconv\n",
            "creating /usr/local/lib/python3.6/dist-packages/groupy/gconv/theano_gconv\n",
            "copying build/lib/groupy/gconv/theano_gconv/__init__.py -> /usr/local/lib/python3.6/dist-packages/groupy/gconv/theano_gconv\n",
            "creating /usr/local/lib/python3.6/dist-packages/groupy/gconv/tensorflow_gconv\n",
            "copying build/lib/groupy/gconv/tensorflow_gconv/__init__.py -> /usr/local/lib/python3.6/dist-packages/groupy/gconv/tensorflow_gconv\n",
            "copying build/lib/groupy/gconv/tensorflow_gconv/splitgconv2d.py -> /usr/local/lib/python3.6/dist-packages/groupy/gconv/tensorflow_gconv\n",
            "copying build/lib/groupy/gconv/tensorflow_gconv/check_transform_filter.py -> /usr/local/lib/python3.6/dist-packages/groupy/gconv/tensorflow_gconv\n",
            "copying build/lib/groupy/gconv/tensorflow_gconv/transform_filter.py -> /usr/local/lib/python3.6/dist-packages/groupy/gconv/tensorflow_gconv\n",
            "copying build/lib/groupy/gconv/tensorflow_gconv/check_gconv2d.py -> /usr/local/lib/python3.6/dist-packages/groupy/gconv/tensorflow_gconv\n",
            "creating /usr/local/lib/python3.6/dist-packages/groupy/gconv/pytorch_gconv\n",
            "copying build/lib/groupy/gconv/pytorch_gconv/check_gconv2d.py -> /usr/local/lib/python3.6/dist-packages/groupy/gconv/pytorch_gconv\n",
            "copying build/lib/groupy/gconv/pytorch_gconv/__init__.py -> /usr/local/lib/python3.6/dist-packages/groupy/gconv/pytorch_gconv\n",
            "copying build/lib/groupy/gconv/pytorch_gconv/check_transform_filter.py -> /usr/local/lib/python3.6/dist-packages/groupy/gconv/pytorch_gconv\n",
            "copying build/lib/groupy/gconv/pytorch_gconv/pooling.py -> /usr/local/lib/python3.6/dist-packages/groupy/gconv/pytorch_gconv\n",
            "copying build/lib/groupy/gconv/pytorch_gconv/splitgconv2d.py -> /usr/local/lib/python3.6/dist-packages/groupy/gconv/pytorch_gconv\n",
            "creating /usr/local/lib/python3.6/dist-packages/groupy/gfunc\n",
            "copying build/lib/groupy/gfunc/z2func_array.py -> /usr/local/lib/python3.6/dist-packages/groupy/gfunc\n",
            "copying build/lib/groupy/gfunc/test_gfuncarray.py -> /usr/local/lib/python3.6/dist-packages/groupy/gfunc\n",
            "copying build/lib/groupy/gfunc/__init__.py -> /usr/local/lib/python3.6/dist-packages/groupy/gfunc\n",
            "copying build/lib/groupy/gfunc/p4func_array.py -> /usr/local/lib/python3.6/dist-packages/groupy/gfunc\n",
            "copying build/lib/groupy/gfunc/gfuncarray.py -> /usr/local/lib/python3.6/dist-packages/groupy/gfunc\n",
            "copying build/lib/groupy/gfunc/p4mfunc_array.py -> /usr/local/lib/python3.6/dist-packages/groupy/gfunc\n",
            "creating /usr/local/lib/python3.6/dist-packages/groupy/gfunc/plot\n",
            "copying build/lib/groupy/gfunc/plot/plot_p4.py -> /usr/local/lib/python3.6/dist-packages/groupy/gfunc/plot\n",
            "copying build/lib/groupy/gfunc/plot/plot_z2.py -> /usr/local/lib/python3.6/dist-packages/groupy/gfunc/plot\n",
            "copying build/lib/groupy/gfunc/plot/__init__.py -> /usr/local/lib/python3.6/dist-packages/groupy/gfunc/plot\n",
            "copying build/lib/groupy/gfunc/plot/plot_p4m.py -> /usr/local/lib/python3.6/dist-packages/groupy/gfunc/plot\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/garray/test_garray.py to test_garray.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/garray/garray.py to garray.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/garray/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/garray/Z2_array.py to Z2_array.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/garray/finitegroup.py to finitegroup.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/garray/matrix_garray.py to matrix_garray.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/garray/C4_array.py to C4_array.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/garray/D4_array.py to D4_array.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/garray/p4m_array.py to p4m_array.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/garray/p4_array.py to p4_array.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/gconv/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/gconv/make_gconv_indices.py to make_gconv_indices.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/gconv/chainer_gconv/transform_filter.py to transform_filter.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/gconv/chainer_gconv/p4_conv.py to p4_conv.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/gconv/chainer_gconv/test_gconv.py to test_gconv.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/gconv/chainer_gconv/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/gconv/chainer_gconv/test_transform_filter.py to test_transform_filter.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/gconv/chainer_gconv/p4m_conv.py to p4m_conv.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/gconv/chainer_gconv/splitgconv2d.py to splitgconv2d.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/gconv/theano_gconv/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/gconv/tensorflow_gconv/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/gconv/tensorflow_gconv/splitgconv2d.py to splitgconv2d.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/gconv/tensorflow_gconv/check_transform_filter.py to check_transform_filter.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/gconv/tensorflow_gconv/transform_filter.py to transform_filter.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/gconv/tensorflow_gconv/check_gconv2d.py to check_gconv2d.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/gconv/pytorch_gconv/check_gconv2d.py to check_gconv2d.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/gconv/pytorch_gconv/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/gconv/pytorch_gconv/check_transform_filter.py to check_transform_filter.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/gconv/pytorch_gconv/pooling.py to pooling.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/gconv/pytorch_gconv/splitgconv2d.py to splitgconv2d.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/gfunc/z2func_array.py to z2func_array.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/gfunc/test_gfuncarray.py to test_gfuncarray.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/gfunc/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/gfunc/p4func_array.py to p4func_array.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/gfunc/gfuncarray.py to gfuncarray.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/gfunc/p4mfunc_array.py to p4mfunc_array.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/gfunc/plot/plot_p4.py to plot_p4.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/gfunc/plot/plot_z2.py to plot_z2.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/gfunc/plot/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/groupy/gfunc/plot/plot_p4m.py to plot_p4m.cpython-36.pyc\n",
            "running install_egg_info\n",
            "Writing /usr/local/lib/python3.6/dist-packages/GrouPy-0.1.2.egg-info\n",
            "groupy.garray.test_garray.test_p4_array ... ok\n",
            "groupy.garray.test_garray.test_p4m_array ... ok\n",
            "groupy.garray.test_garray.test_z2_array ... ok\n",
            "groupy.garray.test_garray.test_c4_array ... ok\n",
            "groupy.garray.test_garray.test_d4_array ... ok\n",
            "Failure: CompileException (/tmp/tmp5k0x_kw9/67c183322e39996272427508ef7205a3_2.cubin.cu(14): error: a value of type \"const ptrdiff_t *\" cannot be used to initialize an entity of type \"const int *\"\n",
            "\n",
            "/tmp/tmp5k0x_kw9/67c183322e39996272427508ef7205a3_2.cubin.cu(15): error: a value of type \"const ptrdiff_t *\" cannot be used to initialize an entity of type \"const int *\"\n",
            "\n",
            "2 errors detected in the compilation of \"/tmp/tmp5k0x_kw9/67c183322e39996272427508ef7205a3_2.cubin.cu\".\n",
            ") ... ERROR\n",
            "groupy.gfunc.test_gfuncarray.test_p4_func ... /content/gdrive/My Drive/Deep Learning/Reproduction project/GrouPy/groupy/gfunc/gfuncarray.py:78: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  vi = self.v[inds]\n",
            "/content/gdrive/My Drive/Deep Learning/Reproduction project/GrouPy/groupy/garray/garray.py:144: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  return self.factory(data=self.data[key], p=self.p)\n",
            "ok\n",
            "groupy.gfunc.test_gfuncarray.test_p4m_func ... ok\n",
            "groupy.gfunc.test_gfuncarray.test_z2_func ... ok\n",
            "\n",
            "======================================================================\n",
            "ERROR: Failure: CompileException (/tmp/tmp5k0x_kw9/67c183322e39996272427508ef7205a3_2.cubin.cu(14): error: a value of type \"const ptrdiff_t *\" cannot be used to initialize an entity of type \"const int *\"\n",
            "\n",
            "/tmp/tmp5k0x_kw9/67c183322e39996272427508ef7205a3_2.cubin.cu(15): error: a value of type \"const ptrdiff_t *\" cannot be used to initialize an entity of type \"const int *\"\n",
            "\n",
            "2 errors detected in the compilation of \"/tmp/tmp5k0x_kw9/67c183322e39996272427508ef7205a3_2.cubin.cu\".\n",
            ")\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/cupy/cuda/compiler.py\", line 242, in compile\n",
            "    nvrtc.compileProgram(self.ptr, options)\n",
            "  File \"cupy/cuda/nvrtc.pyx\", line 98, in cupy.cuda.nvrtc.compileProgram\n",
            "  File \"cupy/cuda/nvrtc.pyx\", line 108, in cupy.cuda.nvrtc.compileProgram\n",
            "  File \"cupy/cuda/nvrtc.pyx\", line 53, in cupy.cuda.nvrtc.check_status\n",
            "cupy.cuda.nvrtc.NVRTCError: NVRTC_ERROR_COMPILATION (6)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/nose/failure.py\", line 39, in runTest\n",
            "    raise self.exc_val.with_traceback(self.tb)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/nose/loader.py\", line 418, in loadTestsFromName\n",
            "    addr.filename, addr.module)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/nose/importer.py\", line 47, in importFromPath\n",
            "    return self.importFromDir(dir_path, fqname)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/nose/importer.py\", line 94, in importFromDir\n",
            "    mod = load_module(part_fqname, fh, filename, desc)\n",
            "  File \"/usr/lib/python3.6/imp.py\", line 245, in load_module\n",
            "    return load_package(name, filename)\n",
            "  File \"/usr/lib/python3.6/imp.py\", line 217, in load_package\n",
            "    return _load(spec)\n",
            "  File \"<frozen importlib._bootstrap>\", line 684, in _load\n",
            "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
            "  File \"/content/gdrive/My Drive/Deep Learning/Reproduction project/GrouPy/groupy/gconv/chainer_gconv/__init__.py\", line 2, in <module>\n",
            "    from groupy.gconv.chainer_gconv.p4_conv import P4ConvZ2, P4ConvP4\n",
            "  File \"/content/gdrive/My Drive/Deep Learning/Reproduction project/GrouPy/groupy/gconv/chainer_gconv/p4_conv.py\", line 1, in <module>\n",
            "    from groupy.gconv.chainer_gconv.splitgconv2d import SplitGConv2D\n",
            "  File \"/content/gdrive/My Drive/Deep Learning/Reproduction project/GrouPy/groupy/gconv/chainer_gconv/splitgconv2d.py\", line 10, in <module>\n",
            "    from groupy.gconv.chainer_gconv.transform_filter import TransformGFilter\n",
            "  File \"/content/gdrive/My Drive/Deep Learning/Reproduction project/GrouPy/groupy/gconv/chainer_gconv/transform_filter.py\", line 8, in <module>\n",
            "    from groupy.gconv.chainer_gconv.kernels.integer_indexing_cuda_kernel import grad_index_group_func_kernel\n",
            "  File \"/content/gdrive/My Drive/Deep Learning/Reproduction project/GrouPy/groupy/gconv/chainer_gconv/kernels/integer_indexing_cuda_kernel.py\", line 61, in <module>\n",
            "    _index_group_func_kernel32 = compile_with_cache(_index_group_func_str.format('float')).get_function('indexing_kernel')\n",
            "  File \"cupy/core/carray.pxi\", line 125, in cupy.core.core.compile_with_cache\n",
            "  File \"cupy/core/carray.pxi\", line 166, in cupy.core.core.compile_with_cache\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/cupy/cuda/compiler.py\", line 165, in compile_with_cache\n",
            "    ptx = compile_using_nvrtc(source, options, arch, name + '.cu')\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/cupy/cuda/compiler.py\", line 81, in compile_using_nvrtc\n",
            "    ptx = prog.compile(options)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/cupy/cuda/compiler.py\", line 246, in compile\n",
            "    raise CompileException(log, self.src, self.name, options)\n",
            "cupy.cuda.compiler.CompileException: /tmp/tmp5k0x_kw9/67c183322e39996272427508ef7205a3_2.cubin.cu(14): error: a value of type \"const ptrdiff_t *\" cannot be used to initialize an entity of type \"const int *\"\n",
            "\n",
            "/tmp/tmp5k0x_kw9/67c183322e39996272427508ef7205a3_2.cubin.cu(15): error: a value of type \"const ptrdiff_t *\" cannot be used to initialize an entity of type \"const int *\"\n",
            "\n",
            "2 errors detected in the compilation of \"/tmp/tmp5k0x_kw9/67c183322e39996272427508ef7205a3_2.cubin.cu\".\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 9 tests in 21.286s\n",
            "\n",
            "FAILED (errors=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3z2qOY12Uscc",
        "colab_type": "text"
      },
      "source": [
        "#Residual Network: Group Equivariant Convolutional Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDkFwMDjVnJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ---------------------------- RESHAPE TENSORS ---------------------------------\n",
        "def reshape_5Dto4D(x):\n",
        "    xs = x.size()\n",
        "    x = x.view(xs[0], xs[1]*xs[2], xs[3], xs[4])\n",
        "    return xs, x\n",
        "    \n",
        "def reshape_4Dto5D(xs, x):\n",
        "    x = x.view(xs[0], xs[1], xs[2], x.size()[2], x.size()[3])\n",
        "    return x\n",
        "\n",
        "\n",
        "# ------------------------------- BASIC BLOCK ----------------------------------\n",
        "class Basic_Block_P4(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downsampling = 1, \n",
        "                 *args,**kwargs):\n",
        "        super(Basic_Block_P4, self).__init__()\n",
        "        self.in_channels  = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.downsampling = downsampling\n",
        "\n",
        "        #convolutions and batch-normalizations\n",
        "        self.g_conv1 = P4ConvP4(in_channels, out_channels, kernel_size=3, \n",
        "                                bias=False, padding = 1, stride = downsampling)\n",
        "        self.bn1     = nn.BatchNorm2d(out_channels*4)\n",
        "        self.g_conv2 = P4ConvP4(out_channels, out_channels, kernel_size=3, \n",
        "                                bias=False, padding = 1)\n",
        "        self.bn2     = nn.BatchNorm2d(out_channels*4)\n",
        "\n",
        "        #shortcut connections\n",
        "        self.id_shortcut   = nn.Sequential()\n",
        "        self.shortcut_conv = P4ConvP4(in_channels, out_channels, kernel_size=1, \n",
        "                                      bias=False, stride = downsampling)\n",
        "        self.shortcut_bn   = nn.BatchNorm2d(out_channels*4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #convolutions, activations and batch-normalizations\n",
        "        out = self.g_conv1(x)\n",
        "        outs, out = reshape_5Dto4D(out)\n",
        "        out = F.relu(self.bn1(out))\n",
        "        out = reshape_4Dto5D(outs, out)\n",
        "        out = self.g_conv2(out)\n",
        "        outs, out = reshape_5Dto4D(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsampling == 1 and self.in_channels == self.out_channels:\n",
        "            x_shorts, x_short = reshape_5Dto4D(x)\n",
        "            x_short = self.id_shortcut(x_short)\n",
        "        elif self.downsampling != 1 or self.in_channels != self.out_channels:\n",
        "            x_short = self.shortcut_conv(x)\n",
        "            x_shorts, x_short = reshape_5Dto4D(x_short)\n",
        "            x_short = self.shortcut_bn(x_short)\n",
        "\n",
        "\n",
        "        #adding both up\n",
        "        out += x_short\n",
        "        out = reshape_4Dto5D(outs, F.relu(out))\n",
        "\n",
        "        return out\n",
        "\n",
        "# -------------------------------- INIT BLOCK ----------------------------------\n",
        "class Init_Block_P4(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downsampling = 1, \n",
        "                 *args,**kwargs):\n",
        "        super(Init_Block_P4, self).__init__()\n",
        "        self.in_channels  = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.downsampling = downsampling\n",
        "\n",
        "        #convolutions and batch-normalizations\n",
        "        self.g_conv1 = P4ConvZ2(in_channels, out_channels, kernel_size=7, \n",
        "                                bias=False, padding = 3, stride = downsampling)\n",
        "        self.bn1     = nn.BatchNorm2d(out_channels*4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #convolutions, activations and batch-normalizations\n",
        "        out = self.g_conv1(x)\n",
        "        outs, out = reshape_5Dto4D(out)\n",
        "        out = F.relu(self.bn1(out))\n",
        "        out = reshape_4Dto5D(outs, out)\n",
        "        return out\n",
        "\n",
        "# ------------------------- ENCODER OF THE NETWORK -----------------------------\n",
        "class ResNet_P4(nn.Module):\n",
        "    '''\n",
        "    This class represents the full implementation of the residual network.\n",
        "    '''\n",
        "    def __init__(self, in_channels, n_classes, \n",
        "                 init_block = Init_Block_P4, resblock = Basic_Block_P4, \n",
        "                 blocks = [16, 32, 64], depths = [7,7,7], *args, **kwargs):\n",
        "        super(ResNet_P4,self).__init__()\n",
        "\n",
        "        \n",
        "        #Encoder part\n",
        "        self.init_conv = Init_Block_P4(in_channels, blocks[0])\n",
        "        self.layer1    = self._residual_layer(blocks[0], blocks[0], resblock, depths[0])\n",
        "        self.layer2    = self._residual_layer(blocks[0], blocks[1], resblock, depths[1])\n",
        "        self.layer3    = self._residual_layer(blocks[1], blocks[2], resblock, depths[2])\n",
        "\n",
        "        #Decoder part\n",
        "        self.avg_pool = nn.AvgPool2d(4)\n",
        "        self.linear1  = nn.Linear(blocks[2]*64*4, n_classes)\n",
        "\n",
        "\n",
        "    def _residual_layer(self, in_channels, out_channels, block, num_blocks, downsampling = 2):\n",
        "        layers = [block(in_channels, out_channels, stride = downsampling)]\n",
        "        for n in range(num_blocks-1):\n",
        "            layers.append(block(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #encoder\n",
        "        out = self.init_conv(x)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        outs, out = reshape_5Dto4D(out)\n",
        "\n",
        "        #decoder part\n",
        "        out = self.avg_pool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear1(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "# -------------------------- TESING OF THE NETWORK -----------------------------\n",
        "def resnet44_P4(in_channels, n_classes):\n",
        "    return ResNet_P4(in_channels, n_classes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TomEUwFxSyFn",
        "colab_type": "text"
      },
      "source": [
        "##Checking Time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGeFHpAhSiuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ---------------------------- RESHAPE TENSORS ---------------------------------\n",
        "def reshape_5Dto4D(x):\n",
        "    xs = x.size()\n",
        "    x = x.view(xs[0], xs[1]*xs[2], xs[3], xs[4])\n",
        "    return xs, x\n",
        "    \n",
        "def reshape_4Dto5D(xs, x):\n",
        "    x = x.view(xs[0], xs[1], xs[2], x.size()[2], x.size()[3])\n",
        "    return x\n",
        "\n",
        "\n",
        "# ------------------------------- BASIC BLOCK ----------------------------------\n",
        "class Basic_Block_P4(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downsampling = 1, \n",
        "                 *args,**kwargs):\n",
        "        super(Basic_Block_P4, self).__init__()\n",
        "        self.in_channels  = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.downsampling = downsampling\n",
        "\n",
        "        #convolutions and batch-normalizations\n",
        "        self.g_conv1 = P4ConvP4(in_channels, out_channels, kernel_size=3, \n",
        "                                bias=False, padding = 1, stride = downsampling)\n",
        "        self.bn1     = nn.BatchNorm2d(out_channels*4)\n",
        "        self.g_conv2 = P4ConvP4(out_channels, out_channels, kernel_size=3, \n",
        "                                bias=False, padding = 1)\n",
        "        self.bn2     = nn.BatchNorm2d(out_channels*4)\n",
        "\n",
        "        #shortcut connections\n",
        "        self.id_shortcut   = nn.Sequential()\n",
        "        self.shortcut_conv = P4ConvP4(in_channels, out_channels, kernel_size=1, \n",
        "                                      bias=False, stride = downsampling)\n",
        "        self.shortcut_bn   = nn.BatchNorm2d(out_channels*4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        print('   NEW SUB AREA: BASIC BLOCK')\n",
        "        start = time.time()\n",
        "        #convolutions, activations and batch-normalizations\n",
        "        out = self.g_conv1(x)\n",
        "        print('   Time check after 1st g_conv:')\n",
        "        print(time.time()-start)\n",
        "        start = time.time()\n",
        "        outs, out = reshape_5Dto4D(out)\n",
        "        print('   Time check after 1st reshape:')\n",
        "        print(time.time()-start)\n",
        "        out = F.relu(self.bn1(out))\n",
        "        out = reshape_4Dto5D(outs, out)\n",
        "        start = time.time()\n",
        "        out = self.g_conv2(out)\n",
        "        print('   Time check after 2nd g_conv:')\n",
        "        print(time.time()-start)\n",
        "        start = time.time()\n",
        "        outs, out = reshape_5Dto4D(out)\n",
        "        print('   Time check after 2nd reshape:')\n",
        "        print(time.time()-start)\n",
        "        start = time.time()\n",
        "        out = self.bn2(out)\n",
        "        print('   Time check after 2nd batchnorm:')\n",
        "        print(time.time()-start)\n",
        "\n",
        "        if self.downsampling == 1 and self.in_channels == self.out_channels:\n",
        "            start = time.time()\n",
        "            x_shorts, x_short = reshape_5Dto4D(x)\n",
        "            print('   Time check after shortcut reshape:')\n",
        "            print(time.time()-start)\n",
        "            x_short = self.id_shortcut(x_short)\n",
        "        elif self.downsampling != 1 or self.in_channels != self.out_channels:\n",
        "            start = time.time()\n",
        "            x_short = self.shortcut_conv(x)\n",
        "            print('   Time check after 1x1 g_conv:')\n",
        "            print(time.time()-start)\n",
        "            start = time.time()\n",
        "            x_shorts, x_short = reshape_5Dto4D(x_short)\n",
        "            print('   Time check after shortcut reshape:')\n",
        "            print(time.time()-start)\n",
        "            start = time.time()\n",
        "            x_short = self.shortcut_bn(x_short)\n",
        "            print('   Time check after shortcut batchnorm:')\n",
        "            print(time.time()-start)\n",
        "\n",
        "        #adding both up\n",
        "        out += x_short\n",
        "        out = reshape_4Dto5D(outs, F.relu(out))\n",
        "        print('   Time check after reshape shortcut + convolution branch:')\n",
        "        print(time.time()-start)\n",
        "\n",
        "        return out\n",
        "\n",
        "# -------------------------------- INIT BLOCK ----------------------------------\n",
        "class Init_Block_P4(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downsampling = 1, \n",
        "                 *args,**kwargs):\n",
        "        super(Init_Block_P4, self).__init__()\n",
        "        self.in_channels  = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.downsampling = downsampling\n",
        "\n",
        "        #convolutions and batch-normalizations\n",
        "        self.g_conv1 = P4ConvZ2(in_channels, out_channels, kernel_size=7, \n",
        "                                bias=False, padding = 3, stride = downsampling)\n",
        "        self.bn1     = nn.BatchNorm2d(out_channels*4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #convolutions, activations and batch-normalizations\n",
        "        print('   NEW SUB AREA: INIT BLOCK')\n",
        "        start = time.time()\n",
        "        out = self.g_conv1(x)\n",
        "        print('   Time check after inital g_conv:')\n",
        "        print(time.time()-start)\n",
        "        start = time.time()\n",
        "        outs, out = reshape_5Dto4D(out)\n",
        "        print('   Time check after reshape 5 --> 4:')\n",
        "        print(time.time()-start)\n",
        "        start = time.time()\n",
        "        out = F.relu(self.bn1(out))\n",
        "        print('   Time check after batch norm:')\n",
        "        print(time.time()-start)\n",
        "        start = time.time()\n",
        "        out = reshape_4Dto5D(outs, out)\n",
        "        print('   Time check after reshape 4 --> 5:')\n",
        "        print(time.time()-start)\n",
        "        return out\n",
        "\n",
        "# ------------------------- ENCODER OF THE NETWORK -----------------------------\n",
        "class ResNet_P4(nn.Module):\n",
        "    '''\n",
        "    This class represents the full implementation of the residual network.\n",
        "    '''\n",
        "    def __init__(self, in_channels, n_classes, \n",
        "                 init_block = Init_Block_P4, resblock = Basic_Block_P4, \n",
        "                 blocks = [16, 32, 64], depths = [7,7,7], *args, **kwargs):\n",
        "        super(ResNet_P4,self).__init__()\n",
        "\n",
        "        \n",
        "        #Encoder part\n",
        "        self.init_conv = Init_Block_P4(in_channels, blocks[0])\n",
        "        self.layer1    = self._residual_layer(blocks[0], blocks[0], resblock, depths[0])\n",
        "        self.layer2    = self._residual_layer(blocks[0], blocks[1], resblock, depths[1])\n",
        "        self.layer3    = self._residual_layer(blocks[1], blocks[2], resblock, depths[2])\n",
        "\n",
        "        #Decoder part\n",
        "        self.avg_pool = nn.AvgPool2d(4)\n",
        "        self.linear1  = nn.Linear(blocks[2]*64*4, n_classes)\n",
        "\n",
        "\n",
        "    def _residual_layer(self, in_channels, out_channels, block, num_blocks, downsampling = 2):\n",
        "        layers = [block(in_channels, out_channels, stride = downsampling)]\n",
        "        for n in range(num_blocks-1):\n",
        "            layers.append(block(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #encoder\n",
        "        print('NEW AREA: INIT BLOCK')\n",
        "        start_whole = time.time()\n",
        "        out = self.init_conv(x)\n",
        "        print('Time check after initial convolution layer:')\n",
        "        print(time.time()-start_whole)\n",
        "        print('')\n",
        "        print('NEW AREA: LAYER 1')\n",
        "        start_whole = time.time()\n",
        "        out = self.layer1(out)\n",
        "        print('Time check after layer 1:')\n",
        "        print(time.time()-start_whole)\n",
        "        print('')\n",
        "        print('NEW AREA: LAYER 2')\n",
        "        start_whole = time.time()\n",
        "        out = self.layer2(out)\n",
        "        print('Time check after layer 2:')\n",
        "        print(time.time()-start_whole)\n",
        "        print('')\n",
        "        print('NEW AREA: LAYER 3')\n",
        "        start_whole = time.time()\n",
        "        out = self.layer3(out)\n",
        "        print('Time check after layer 3:')\n",
        "        print(time.time()-start_whole)\n",
        "        start_whole = time.time()\n",
        "        outs, out = reshape_5Dto4D(out)\n",
        "        print('Time check after final reshape:')\n",
        "        print(time.time()-start_whole)\n",
        "\n",
        "        #decoder part\n",
        "        print('')\n",
        "        print('NEW AREA: FULLY CONNECTED')\n",
        "        start_whole = time.time()\n",
        "        out = self.avg_pool(out)\n",
        "        print(' Time check after final average pooling:')\n",
        "        print(time.time()-start_whole)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        start_whole = time.time()\n",
        "        out = self.linear1(out)\n",
        "        print(' Time check final linear layer:')\n",
        "        print(time.time()-start_whole)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "# -------------------------- TESING OF THE NETWORK -----------------------------\n",
        "def resnet44_P4(in_channels, n_classes):\n",
        "    return ResNet_P4(in_channels, n_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKmwInwcRn26",
        "colab_type": "code",
        "outputId": "44410177-474f-4f82-af6f-24a4fd1d22c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def resnet_p4_test(in_channels, out_channels):\n",
        "    return ResNet_P4(in_channels, out_channels)\n",
        "\n",
        "resnet_p4_test = resnet_p4_test(3, 10)\n",
        "\n",
        "evaluate_accuracy(testloader, resnet_p4_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NEW AREA: INIT BLOCK\n",
            "   NEW SUB AREA: INIT BLOCK\n",
            "   Time check after inital g_conv:\n",
            "0.13975310325622559\n",
            "   Time check after reshape 5 --> 4:\n",
            "9.584426879882812e-05\n",
            "   Time check after batch norm:\n",
            "0.05186009407043457\n",
            "   Time check after reshape 4 --> 5:\n",
            "0.0007143020629882812\n",
            "Time check after initial convolution layer:\n",
            "0.19375944137573242\n",
            "\n",
            "NEW AREA: LAYER 1\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "0.19710946083068848\n",
            "   Time check after 1st reshape:\n",
            "0.0005748271942138672\n",
            "   Time check after 2nd g_conv:\n",
            "0.1714458465576172\n",
            "   Time check after 2nd reshape:\n",
            "0.0007448196411132812\n",
            "   Time check after 2nd batchnorm:\n",
            "0.011172771453857422\n",
            "   Time check after shortcut reshape:\n",
            "0.0003726482391357422\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.018550634384155273\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "0.15905189514160156\n",
            "   Time check after 1st reshape:\n",
            "0.00043654441833496094\n",
            "   Time check after 2nd g_conv:\n",
            "0.16347217559814453\n",
            "   Time check after 2nd reshape:\n",
            "0.0007491111755371094\n",
            "   Time check after 2nd batchnorm:\n",
            "0.01189422607421875\n",
            "   Time check after shortcut reshape:\n",
            "0.0003895759582519531\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.019600868225097656\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "0.15842747688293457\n",
            "   Time check after 1st reshape:\n",
            "0.0004911422729492188\n",
            "   Time check after 2nd g_conv:\n",
            "0.16571521759033203\n",
            "   Time check after 2nd reshape:\n",
            "7.867813110351562e-05\n",
            "   Time check after 2nd batchnorm:\n",
            "0.011419057846069336\n",
            "   Time check after shortcut reshape:\n",
            "0.0004425048828125\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.018879175186157227\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "0.17051935195922852\n",
            "   Time check after 1st reshape:\n",
            "8.463859558105469e-05\n",
            "   Time check after 2nd g_conv:\n",
            "0.16457009315490723\n",
            "   Time check after 2nd reshape:\n",
            "0.00051116943359375\n",
            "   Time check after 2nd batchnorm:\n",
            "0.012853384017944336\n",
            "   Time check after shortcut reshape:\n",
            "0.000438690185546875\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.020362377166748047\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "0.16505789756774902\n",
            "   Time check after 1st reshape:\n",
            "0.0004355907440185547\n",
            "   Time check after 2nd g_conv:\n",
            "0.15901446342468262\n",
            "   Time check after 2nd reshape:\n",
            "0.0006461143493652344\n",
            "   Time check after 2nd batchnorm:\n",
            "0.010985374450683594\n",
            "   Time check after shortcut reshape:\n",
            "0.0005061626434326172\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.01857590675354004\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "0.16164326667785645\n",
            "   Time check after 1st reshape:\n",
            "0.0003516674041748047\n",
            "   Time check after 2nd g_conv:\n",
            "0.16736888885498047\n",
            "   Time check after 2nd reshape:\n",
            "8.559226989746094e-05\n",
            "   Time check after 2nd batchnorm:\n",
            "0.01187443733215332\n",
            "   Time check after shortcut reshape:\n",
            "0.0004584789276123047\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.020527124404907227\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "0.16805648803710938\n",
            "   Time check after 1st reshape:\n",
            "8.392333984375e-05\n",
            "   Time check after 2nd g_conv:\n",
            "0.15703082084655762\n",
            "   Time check after 2nd reshape:\n",
            "0.0004475116729736328\n",
            "   Time check after 2nd batchnorm:\n",
            "0.011193513870239258\n",
            "   Time check after shortcut reshape:\n",
            "0.00046372413635253906\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.01939082145690918\n",
            "Time check after layer 1:\n",
            "2.763824701309204\n",
            "\n",
            "NEW AREA: LAYER 2\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "0.3820364475250244\n",
            "   Time check after 1st reshape:\n",
            "0.0006322860717773438\n",
            "   Time check after 2nd g_conv:\n",
            "0.6372694969177246\n",
            "   Time check after 2nd reshape:\n",
            "0.00011396408081054688\n",
            "   Time check after 2nd batchnorm:\n",
            "0.02230691909790039\n",
            "   Time check after 1x1 g_conv:\n",
            "0.10471701622009277\n",
            "   Time check after shortcut reshape:\n",
            "0.0004706382751464844\n",
            "   Time check after shortcut batchnorm:\n",
            "0.022939205169677734\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.06522035598754883\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "0.6288785934448242\n",
            "   Time check after 1st reshape:\n",
            "0.0005376338958740234\n",
            "   Time check after 2nd g_conv:\n",
            "0.608579158782959\n",
            "   Time check after 2nd reshape:\n",
            "0.000579833984375\n",
            "   Time check after 2nd batchnorm:\n",
            "0.02364516258239746\n",
            "   Time check after shortcut reshape:\n",
            "0.0004258155822753906\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.041083335876464844\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "0.5787467956542969\n",
            "   Time check after 1st reshape:\n",
            "0.0005331039428710938\n",
            "   Time check after 2nd g_conv:\n",
            "0.5981650352478027\n",
            "   Time check after 2nd reshape:\n",
            "0.00018548965454101562\n",
            "   Time check after 2nd batchnorm:\n",
            "0.024897098541259766\n",
            "   Time check after shortcut reshape:\n",
            "0.0006389617919921875\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.04097151756286621\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "0.603060245513916\n",
            "   Time check after 1st reshape:\n",
            "0.0006487369537353516\n",
            "   Time check after 2nd g_conv:\n",
            "0.6223239898681641\n",
            "   Time check after 2nd reshape:\n",
            "5.53131103515625e-05\n",
            "   Time check after 2nd batchnorm:\n",
            "0.023382902145385742\n",
            "   Time check after shortcut reshape:\n",
            "0.0004668235778808594\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.03791308403015137\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "0.6307563781738281\n",
            "   Time check after 1st reshape:\n",
            "0.0005888938903808594\n",
            "   Time check after 2nd g_conv:\n",
            "0.6440305709838867\n",
            "   Time check after 2nd reshape:\n",
            "6.842613220214844e-05\n",
            "   Time check after 2nd batchnorm:\n",
            "0.02753615379333496\n",
            "   Time check after shortcut reshape:\n",
            "0.0001456737518310547\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.040995121002197266\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "0.6100621223449707\n",
            "   Time check after 1st reshape:\n",
            "0.0005125999450683594\n",
            "   Time check after 2nd g_conv:\n",
            "0.6322858333587646\n",
            "   Time check after 2nd reshape:\n",
            "0.0006160736083984375\n",
            "   Time check after 2nd batchnorm:\n",
            "0.023180007934570312\n",
            "   Time check after shortcut reshape:\n",
            "0.0006153583526611328\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.040461063385009766\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "0.6028883457183838\n",
            "   Time check after 1st reshape:\n",
            "9.226799011230469e-05\n",
            "   Time check after 2nd g_conv:\n",
            "0.5941944122314453\n",
            "   Time check after 2nd reshape:\n",
            "9.369850158691406e-05\n",
            "   Time check after 2nd batchnorm:\n",
            "0.024051666259765625\n",
            "   Time check after shortcut reshape:\n",
            "0.0003457069396972656\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.03960061073303223\n",
            "Time check after layer 2:\n",
            "9.368643999099731\n",
            "\n",
            "NEW AREA: LAYER 3\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "1.2884478569030762\n",
            "   Time check after 1st reshape:\n",
            "0.0006632804870605469\n",
            "   Time check after 2nd g_conv:\n",
            "2.346069812774658\n",
            "   Time check after 2nd reshape:\n",
            "0.00019431114196777344\n",
            "   Time check after 2nd batchnorm:\n",
            "0.04485273361206055\n",
            "   Time check after 1x1 g_conv:\n",
            "0.4015209674835205\n",
            "   Time check after shortcut reshape:\n",
            "5.841255187988281e-05\n",
            "   Time check after shortcut batchnorm:\n",
            "0.045723915100097656\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.12310361862182617\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "2.24235200881958\n",
            "   Time check after 1st reshape:\n",
            "0.0003066062927246094\n",
            "   Time check after 2nd g_conv:\n",
            "2.28617000579834\n",
            "   Time check after 2nd reshape:\n",
            "7.152557373046875e-05\n",
            "   Time check after 2nd batchnorm:\n",
            "0.04537510871887207\n",
            "   Time check after shortcut reshape:\n",
            "0.0004532337188720703\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.0767369270324707\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "2.253059148788452\n",
            "   Time check after 1st reshape:\n",
            "0.0002732276916503906\n",
            "   Time check after 2nd g_conv:\n",
            "2.279546022415161\n",
            "   Time check after 2nd reshape:\n",
            "0.000659942626953125\n",
            "   Time check after 2nd batchnorm:\n",
            "0.04534006118774414\n",
            "   Time check after shortcut reshape:\n",
            "0.0005087852478027344\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.07779288291931152\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "2.2901699542999268\n",
            "   Time check after 1st reshape:\n",
            "0.00027942657470703125\n",
            "   Time check after 2nd g_conv:\n",
            "2.260401725769043\n",
            "   Time check after 2nd reshape:\n",
            "7.987022399902344e-05\n",
            "   Time check after 2nd batchnorm:\n",
            "0.046807050704956055\n",
            "   Time check after shortcut reshape:\n",
            "0.00048732757568359375\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.07943844795227051\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "2.22564435005188\n",
            "   Time check after 1st reshape:\n",
            "0.0006189346313476562\n",
            "   Time check after 2nd g_conv:\n",
            "2.237428903579712\n",
            "   Time check after 2nd reshape:\n",
            "7.867813110351562e-05\n",
            "   Time check after 2nd batchnorm:\n",
            "0.04577445983886719\n",
            "   Time check after shortcut reshape:\n",
            "0.0004723072052001953\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.07852888107299805\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "2.22448992729187\n",
            "   Time check after 1st reshape:\n",
            "0.00016307830810546875\n",
            "   Time check after 2nd g_conv:\n",
            "2.2697479724884033\n",
            "   Time check after 2nd reshape:\n",
            "8.535385131835938e-05\n",
            "   Time check after 2nd batchnorm:\n",
            "0.044934988021850586\n",
            "   Time check after shortcut reshape:\n",
            "0.0005140304565429688\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.07830071449279785\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "2.311652898788452\n",
            "   Time check after 1st reshape:\n",
            "0.0007796287536621094\n",
            "   Time check after 2nd g_conv:\n",
            "2.258258581161499\n",
            "   Time check after 2nd reshape:\n",
            "0.00018334388732910156\n",
            "   Time check after 2nd batchnorm:\n",
            "0.04740500450134277\n",
            "   Time check after shortcut reshape:\n",
            "0.0005061626434326172\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.08300542831420898\n",
            "Time check after layer 3:\n",
            "32.814621925354004\n",
            "Time check after final reshape:\n",
            "8.463859558105469e-05\n",
            "\n",
            "NEW AREA: FULLY CONNECTED\n",
            " Time check after final average pooling:\n",
            "0.04811358451843262\n",
            " Time check final linear layer:\n",
            "0.0035758018493652344\n",
            "NEW AREA: INIT BLOCK\n",
            "   NEW SUB AREA: INIT BLOCK\n",
            "   Time check after inital g_conv:\n",
            "0.07507824897766113\n",
            "   Time check after reshape 5 --> 4:\n",
            "0.0005898475646972656\n",
            "   Time check after batch norm:\n",
            "0.022021055221557617\n",
            "   Time check after reshape 4 --> 5:\n",
            "0.0006043910980224609\n",
            "Time check after initial convolution layer:\n",
            "0.09853887557983398\n",
            "\n",
            "NEW AREA: LAYER 1\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "0.161848783493042\n",
            "   Time check after 1st reshape:\n",
            "0.0001838207244873047\n",
            "   Time check after 2nd g_conv:\n",
            "0.16490983963012695\n",
            "   Time check after 2nd reshape:\n",
            "0.00063323974609375\n",
            "   Time check after 2nd batchnorm:\n",
            "0.012249469757080078\n",
            "   Time check after shortcut reshape:\n",
            "9.465217590332031e-05\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.020478248596191406\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "0.17102599143981934\n",
            "   Time check after 1st reshape:\n",
            "6.4849853515625e-05\n",
            "   Time check after 2nd g_conv:\n",
            "0.16140174865722656\n",
            "   Time check after 2nd reshape:\n",
            "0.00019216537475585938\n",
            "   Time check after 2nd batchnorm:\n",
            "0.012052059173583984\n",
            "   Time check after shortcut reshape:\n",
            "0.0004851818084716797\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.020618915557861328\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "0.18059206008911133\n",
            "   Time check after 1st reshape:\n",
            "0.00010371208190917969\n",
            "   Time check after 2nd g_conv:\n",
            "0.15540671348571777\n",
            "   Time check after 2nd reshape:\n",
            "0.0005803108215332031\n",
            "   Time check after 2nd batchnorm:\n",
            "0.010800361633300781\n",
            "   Time check after shortcut reshape:\n",
            "0.00018858909606933594\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.01839160919189453\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "0.15742039680480957\n",
            "   Time check after 1st reshape:\n",
            "0.00015616416931152344\n",
            "   Time check after 2nd g_conv:\n",
            "0.15511155128479004\n",
            "   Time check after 2nd reshape:\n",
            "0.0005371570587158203\n",
            "   Time check after 2nd batchnorm:\n",
            "0.010680437088012695\n",
            "   Time check after shortcut reshape:\n",
            "0.0001316070556640625\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.018445730209350586\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "0.1519927978515625\n",
            "   Time check after 1st reshape:\n",
            "0.0005040168762207031\n",
            "   Time check after 2nd g_conv:\n",
            "0.16117024421691895\n",
            "   Time check after 2nd reshape:\n",
            "0.00019788742065429688\n",
            "   Time check after 2nd batchnorm:\n",
            "0.01144099235534668\n",
            "   Time check after shortcut reshape:\n",
            "0.0005233287811279297\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.019173145294189453\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "0.17269062995910645\n",
            "   Time check after 1st reshape:\n",
            "4.7206878662109375e-05\n",
            "   Time check after 2nd g_conv:\n",
            "0.15862631797790527\n",
            "   Time check after 2nd reshape:\n",
            "0.0006396770477294922\n",
            "   Time check after 2nd batchnorm:\n",
            "0.01219320297241211\n",
            "   Time check after shortcut reshape:\n",
            "0.00045108795166015625\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.021234989166259766\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "0.15598487854003906\n",
            "   Time check after 1st reshape:\n",
            "0.0006077289581298828\n",
            "   Time check after 2nd g_conv:\n",
            "0.16690921783447266\n",
            "   Time check after 2nd reshape:\n",
            "0.00037550926208496094\n",
            "   Time check after 2nd batchnorm:\n",
            "0.01157999038696289\n",
            "   Time check after shortcut reshape:\n",
            "0.0005533695220947266\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.019565820693969727\n",
            "Time check after layer 1:\n",
            "2.6687769889831543\n",
            "\n",
            "NEW AREA: LAYER 2\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "0.32555699348449707\n",
            "   Time check after 1st reshape:\n",
            "0.0005402565002441406\n",
            "   Time check after 2nd g_conv:\n",
            "0.5902280807495117\n",
            "   Time check after 2nd reshape:\n",
            "0.0005345344543457031\n",
            "   Time check after 2nd batchnorm:\n",
            "0.024079561233520508\n",
            "   Time check after 1x1 g_conv:\n",
            "0.08162450790405273\n",
            "   Time check after shortcut reshape:\n",
            "0.0002124309539794922\n",
            "   Time check after shortcut batchnorm:\n",
            "0.024500370025634766\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.06444025039672852\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "0.6033742427825928\n",
            "   Time check after 1st reshape:\n",
            "9.870529174804688e-05\n",
            "   Time check after 2nd g_conv:\n",
            "0.6048710346221924\n",
            "   Time check after 2nd reshape:\n",
            "0.00019812583923339844\n",
            "   Time check after 2nd batchnorm:\n",
            "0.02299022674560547\n",
            "   Time check after shortcut reshape:\n",
            "0.00026035308837890625\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.041486263275146484\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "0.6107914447784424\n",
            "   Time check after 1st reshape:\n",
            "0.0001537799835205078\n",
            "   Time check after 2nd g_conv:\n",
            "0.5950658321380615\n",
            "   Time check after 2nd reshape:\n",
            "0.0009713172912597656\n",
            "   Time check after 2nd batchnorm:\n",
            "0.025208234786987305\n",
            "   Time check after shortcut reshape:\n",
            "0.0005373954772949219\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.041135549545288086\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "0.5987975597381592\n",
            "   Time check after 1st reshape:\n",
            "0.0010116100311279297\n",
            "   Time check after 2nd g_conv:\n",
            "0.588451623916626\n",
            "   Time check after 2nd reshape:\n",
            "0.0006191730499267578\n",
            "   Time check after 2nd batchnorm:\n",
            "0.022439002990722656\n",
            "   Time check after shortcut reshape:\n",
            "0.0002701282501220703\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.04109764099121094\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "0.6098687648773193\n",
            "   Time check after 1st reshape:\n",
            "0.00017976760864257812\n",
            "   Time check after 2nd g_conv:\n",
            "0.582585334777832\n",
            "   Time check after 2nd reshape:\n",
            "0.0006692409515380859\n",
            "   Time check after 2nd batchnorm:\n",
            "0.027249574661254883\n",
            "   Time check after shortcut reshape:\n",
            "0.00043487548828125\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.040377140045166016\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "0.5923116207122803\n",
            "   Time check after 1st reshape:\n",
            "0.0006086826324462891\n",
            "   Time check after 2nd g_conv:\n",
            "0.59828782081604\n",
            "   Time check after 2nd reshape:\n",
            "0.0005576610565185547\n",
            "   Time check after 2nd batchnorm:\n",
            "0.022284746170043945\n",
            "   Time check after shortcut reshape:\n",
            "0.00010180473327636719\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.03869032859802246\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "0.5803282260894775\n",
            "   Time check after 1st reshape:\n",
            "0.0004813671112060547\n",
            "   Time check after 2nd g_conv:\n",
            "0.6044108867645264\n",
            "   Time check after 2nd reshape:\n",
            "0.0009107589721679688\n",
            "   Time check after 2nd batchnorm:\n",
            "0.024147510528564453\n",
            "   Time check after shortcut reshape:\n",
            "0.0007314682006835938\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.04004216194152832\n",
            "Time check after layer 2:\n",
            "8.98455262184143\n",
            "\n",
            "NEW AREA: LAYER 3\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "1.1476354598999023\n",
            "   Time check after 1st reshape:\n",
            "0.0001595020294189453\n",
            "   Time check after 2nd g_conv:\n",
            "2.241084098815918\n",
            "   Time check after 2nd reshape:\n",
            "0.00034117698669433594\n",
            "   Time check after 2nd batchnorm:\n",
            "0.0482027530670166\n",
            "   Time check after 1x1 g_conv:\n",
            "0.3369615077972412\n",
            "   Time check after shortcut reshape:\n",
            "0.0006737709045410156\n",
            "   Time check after shortcut batchnorm:\n",
            "0.04531550407409668\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.12396740913391113\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "2.273183822631836\n",
            "   Time check after 1st reshape:\n",
            "8.749961853027344e-05\n",
            "   Time check after 2nd g_conv:\n",
            "2.247061014175415\n",
            "   Time check after 2nd reshape:\n",
            "0.00025010108947753906\n",
            "   Time check after 2nd batchnorm:\n",
            "0.04413652420043945\n",
            "   Time check after shortcut reshape:\n",
            "0.00037598609924316406\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.07506704330444336\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "2.2783801555633545\n",
            "   Time check after 1st reshape:\n",
            "0.0009253025054931641\n",
            "   Time check after 2nd g_conv:\n",
            "2.2637627124786377\n",
            "   Time check after 2nd reshape:\n",
            "0.0007126331329345703\n",
            "   Time check after 2nd batchnorm:\n",
            "0.04534506797790527\n",
            "   Time check after shortcut reshape:\n",
            "0.00016689300537109375\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.07721161842346191\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "2.300657033920288\n",
            "   Time check after 1st reshape:\n",
            "0.0005981922149658203\n",
            "   Time check after 2nd g_conv:\n",
            "2.2513272762298584\n",
            "   Time check after 2nd reshape:\n",
            "0.0006546974182128906\n",
            "   Time check after 2nd batchnorm:\n",
            "0.046086788177490234\n",
            "   Time check after shortcut reshape:\n",
            "0.00043964385986328125\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.08007931709289551\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "2.2649943828582764\n",
            "   Time check after 1st reshape:\n",
            "0.00015425682067871094\n",
            "   Time check after 2nd g_conv:\n",
            "2.2554640769958496\n",
            "   Time check after 2nd reshape:\n",
            "8.821487426757812e-05\n",
            "   Time check after 2nd batchnorm:\n",
            "0.046715736389160156\n",
            "   Time check after shortcut reshape:\n",
            "0.00043463706970214844\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.08816170692443848\n",
            "   NEW SUB AREA: BASIC BLOCK\n",
            "   Time check after 1st g_conv:\n",
            "2.24749755859375\n",
            "   Time check after 1st reshape:\n",
            "0.0005567073822021484\n",
            "   Time check after 2nd g_conv:\n",
            "2.273177146911621\n",
            "   Time check after 2nd reshape:\n",
            "0.0007662773132324219\n",
            "   Time check after 2nd batchnorm:\n",
            "0.04554915428161621\n",
            "   Time check after shortcut reshape:\n",
            "0.00014448165893554688\n",
            "   Time check after reshape shortcut + convolution branch:\n",
            "0.0799400806427002\n",
            "   NEW SUB AREA: BASIC BLOCK\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-ea1b45a28ec6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mresnet_p4_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet_p4_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mevaluate_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnet_p4_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-3295008555b2>\u001b[0m in \u001b[0;36mevaluate_accuracy\u001b[0;34m(data_iter, net, device)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0macc_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0macc_sum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-26146bb3be95>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NEW AREA: LAYER 3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mstart_whole\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Time check after layer 3:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart_whole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-26146bb3be95>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m#convolutions, activations and batch-normalizations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_conv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'   Time check after 1st g_conv:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gdrive/My Drive/Deep Learning/Reproduction project/GrouPy/groupy/gconv/pytorch_gconv/splitgconv2d.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         y = F.conv2d(input, weight=tw, bias=None, stride=self.stride,\n\u001b[0;32m---> 77\u001b[0;31m                         padding=self.padding)\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mny_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnx_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_stabilizer_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mny_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnx_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VR09H2x9_WtJ",
        "colab_type": "text"
      },
      "source": [
        "##P4 and P4M integrated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JuEhc_s_c09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ---------------------------- RESHAPE TENSORS ---------------------------------\n",
        "def reshape_5Dto4D(x):\n",
        "    xs = x.size()\n",
        "    x = x.view(xs[0], xs[1]*xs[2], xs[3], xs[4])\n",
        "    return xs, x\n",
        "    \n",
        "def reshape_4Dto5D(xs, x):\n",
        "    x = x.view(xs[0], xs[1], xs[2], x.size()[2], x.size()[3])\n",
        "    return x\n",
        "\n",
        "\n",
        "# ------------------------------- BASIC BLOCK ----------------------------------\n",
        "class Basic_Block_G(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downsampling = 1, \n",
        "                 num_trans = 4, g_conv = P4ConvP4, *args,**kwargs):\n",
        "        super(Basic_Block_G, self).__init__()\n",
        "        self.in_channels  = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.downsampling = downsampling\n",
        "        self.num_trans    = num_trans\n",
        "\n",
        "        #convolutions and batch-normalizations\n",
        "        self.g_conv1 = g_conv(in_channels, out_channels, kernel_size=3, \n",
        "                                bias=False, padding = 1, stride = downsampling)\n",
        "        self.bn1     = nn.BatchNorm2d(out_channels*num_trans)\n",
        "        self.g_conv2 = g_conv(out_channels, out_channels, kernel_size=3, \n",
        "                                bias=False, padding = 1)\n",
        "        self.bn2     = nn.BatchNorm2d(out_channels*num_trans)\n",
        "\n",
        "        #shortcut connections\n",
        "        self.id_shortcut   = nn.Sequential()\n",
        "        self.shortcut_conv = g_conv(in_channels, out_channels, kernel_size=1, \n",
        "                                      bias=False, stride = downsampling)\n",
        "        self.shortcut_bn   = nn.BatchNorm2d(out_channels*num_trans)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #convolutions, activations and batch-normalizations\n",
        "        out = self.g_conv1(x)\n",
        "        outs, out = reshape_5Dto4D(out)\n",
        "        out = F.relu(self.bn1(out))\n",
        "        out = reshape_4Dto5D(outs, out)\n",
        "        out = self.g_conv2(out)\n",
        "        outs, out = reshape_5Dto4D(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsampling == 1 and self.in_channels == self.out_channels:\n",
        "            x_shorts, x_short = reshape_5Dto4D(x)\n",
        "            x_short = self.id_shortcut(x_short)\n",
        "        elif self.downsampling != 1 or self.in_channels != self.out_channels:\n",
        "            x_short = self.shortcut_conv(x)\n",
        "            x_shorts, x_short = reshape_5Dto4D(x_short)\n",
        "            x_short = self.shortcut_bn(x_short)\n",
        "\n",
        "\n",
        "        #adding both up\n",
        "        out += x_short\n",
        "        out = reshape_4Dto5D(outs, F.relu(out))\n",
        "\n",
        "        return out\n",
        "\n",
        "# -------------------------------- INIT BLOCK ----------------------------------\n",
        "class Init_Block_G(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downsampling = 1,\n",
        "                 num_trans = 4, g_conv = P4ConvP4,\n",
        "                 *args,**kwargs):\n",
        "        super(Init_Block_G, self).__init__()\n",
        "        self.in_channels  = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.downsampling = downsampling\n",
        "\n",
        "        #convolutions and batch-normalizations\n",
        "        self.g_conv1 = g_conv(in_channels, out_channels, kernel_size=7, \n",
        "                                bias=False, padding = 3, stride = downsampling)\n",
        "        self.bn1     = nn.BatchNorm2d(out_channels*num_trans)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #convolutions, activations and batch-normalizations\n",
        "        out = self.g_conv1(x)\n",
        "        outs, out = reshape_5Dto4D(out)\n",
        "        out = F.relu(self.bn1(out))\n",
        "        out = reshape_4Dto5D(outs, out)\n",
        "        return out\n",
        "\n",
        "# ------------------------- ENCODER OF THE NETWORK -----------------------------\n",
        "class ResNet_G(nn.Module):\n",
        "    '''\n",
        "    This class represents the full implementation of the residual network.\n",
        "    '''\n",
        "    def __init__(self, in_channels, n_classes, \n",
        "                 init_block = Init_Block_G, resblock = Basic_Block_G, \n",
        "                 blocks = [16, 32, 64], depths = [7,7,7],\n",
        "                 num_trans = 4, *args, **kwargs):\n",
        "        super(ResNet_G,self).__init__()\n",
        "        self.num_trans = num_trans\n",
        "\n",
        "        #Chose between symmetry groups\n",
        "        if self.num_trans == 4:\n",
        "            self.g_conv      = P4ConvP4\n",
        "            self.g_conv_init = P4ConvZ2\n",
        "        elif self.num_trans == 8:\n",
        "            self.g_conv      = P4MConvP4M\n",
        "            self.g_conv_init = P4MConvZ2\n",
        "\n",
        "        \n",
        "        #Encoder part\n",
        "        self.init_conv = Init_Block_G(in_channels, blocks[0], \n",
        "                                      num_trans = self.num_trans, g_conv = self.g_conv_init)\n",
        "        self.layer1    = self._residual_layer(blocks[0], blocks[0], resblock, depths[0])\n",
        "        self.layer2    = self._residual_layer(blocks[0], blocks[1], resblock, depths[1])\n",
        "        self.layer3    = self._residual_layer(blocks[1], blocks[2], resblock, depths[2])\n",
        "\n",
        "        #Decoder part\n",
        "        self.avg_pool = nn.AvgPool2d(4)\n",
        "        self.linear1  = nn.Linear(blocks[2]*64*self.num_trans, n_classes)\n",
        "\n",
        "\n",
        "    def _residual_layer(self, in_channels, out_channels, block, num_blocks, downsampling = 2):\n",
        "        layers = [block(in_channels, out_channels, stride = downsampling, \n",
        "                                num_trans = self.num_trans, g_conv = self.g_conv)]\n",
        "        for n in range(num_blocks-1):\n",
        "            layers.append(block(out_channels, out_channels, \n",
        "                                num_trans = self.num_trans, g_conv = self.g_conv))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #encoder\n",
        "        out = self.init_conv(x)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        outs, out = reshape_5Dto4D(out)\n",
        "\n",
        "        #decoder part\n",
        "        out = self.avg_pool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear1(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "# -------------------------- TESING OF THE NETWORK -----------------------------\n",
        "def resnet44_P4(in_channels, n_classes):\n",
        "    return ResNet_G(in_channels, n_classes)\n",
        "\n",
        "def resnet44_P4M(in_channels, n_classes):\n",
        "    return ResNet_G(in_channels, n_classes, blocks = [11, 23, 45], num_trans = 8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL14yNU44d6b",
        "colab_type": "text"
      },
      "source": [
        "##Faster implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqKhcF4a4hbW",
        "colab_type": "code",
        "outputId": "94ac9df1-b33b-4682-d2ea-4c5cb42318f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "# ---------------------------- RESHAPE TENSORS ---------------------------------\n",
        "def reshape_5Dto4D(x):\n",
        "    xs = x.size()\n",
        "    x = x.view(xs[0], xs[1]*xs[2], xs[3], xs[4])\n",
        "    return xs, x\n",
        "    \n",
        "def reshape_4Dto5D(xs, x):\n",
        "    x = x.view(xs[0], xs[1], xs[2], x.size()[2], x.size()[3])\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --------------------------- CLASS RESHAPE ------------------------------------\n",
        "#4D to 5D\n",
        "class Reshape_4Dto5D(nn.Module):\n",
        "    def __init__(self, xs):\n",
        "        super().__init__()\n",
        "        self.xs = xs\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = x.view(xs[0], xs[1], xs[2], x.size()[0], x.size()[1])\n",
        "        return x\n",
        "\n",
        "#5D to 4D\n",
        "class Reshape_5Dto4D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self,x):\n",
        "        xs = x.size()\n",
        "        x = x.view(xs[0], xs[1]*xs[2], xs[3], xs[4])\n",
        "        return xs, x\n",
        "\n",
        "\n",
        "\n",
        "# -------------------------- G-CONV within nn.Module ---------------------------\n",
        "class G_P4P4(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downsampling = 1, bias = False, \n",
        "                 padding = 1):\n",
        "        super().__init__()\n",
        "        self.g_conv = P4ConvP4(in_channels, out_channels, stride = downsampling, \n",
        "                               bias = bias, padding = padding)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.g_conv(x)\n",
        "        return x\n",
        "\n",
        "class G_P4Z2(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downsampling = 1, bias = False, \n",
        "                 padding = 1):\n",
        "        super().__init__()\n",
        "        self.g_conv = P4ConvZ2(in_channels, out_channels, stride = downsampling, \n",
        "                               bias = bias, padding = padding)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.g_conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "# ------------------------ CLASS RESIDUAL BLOCK --------------------------------\n",
        "# In:  pre-activated 5D array: [batch_size, n_channels_in, n_transformations, height_in, width_in]\n",
        "# Out: pre-activated 5D array: [batch_size, n_channels_out, n_transformations,  height_out, width_out]\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.in_channels, self.out_channels =  in_channels, out_channels\n",
        "        self.blocks   = nn.Identity() #initialize block as identity\n",
        "        self.shortcut = nn.Identity() #initialize skip as identity\n",
        "    \n",
        "    def forward(self, x):\n",
        "        #shortcut\n",
        "        residual = x\n",
        "        if self.should_apply_shortcut: residual = self.shortcut(x)\n",
        "        x = self.blocks(x)\n",
        "\n",
        "        #combination\n",
        "        x += residual\n",
        "        x = F.relu(x)\n",
        "        return x\n",
        "    \n",
        "    @property\n",
        "    def should_apply_shortcut(self):\n",
        "        return self.in_channels != self.out_channels\n",
        "\n",
        "\n",
        "# ----------------------- CLASS RESNET RESIDUAL BLOCK --------------------------\n",
        "class ResNetResidualBlock(ResidualBlock):\n",
        "    def __init__(self, in_channels, out_channels, expansion=1, downsampling=1, \n",
        "                 conv=P4ConvP4, *args, **kwargs):\n",
        "        super().__init__(in_channels, out_channels)\n",
        "        self.expansion, self.downsampling, self.conv = expansion, downsampling, conv\n",
        "\n",
        "        self.shortcut = nn.Sequential(OrderedDict({\n",
        "            'conv' : P4ConvP4(self.in_channels, \n",
        "                                self.expanded_channels, kernel_size=1,\n",
        "                                stride=self.downsampling, bias=False),\n",
        "            'bn'   : nn.BatchNorm3d(self.expanded_channels)\n",
        "            \n",
        "        })) if self.should_apply_shortcut else None \n",
        "\n",
        "        \n",
        "    @property\n",
        "    def expanded_channels(self):\n",
        "        return self.out_channels * self.expansion\n",
        "    \n",
        "    @property\n",
        "    def should_apply_shortcut(self):\n",
        "        return self.in_channels != self.expanded_channels\n",
        "\n",
        "\n",
        "\n",
        "# --------------------- PRE CONVOLUTION SEQUENTIAL -----------------------------\n",
        "def bn_conv(in_channels, out_channels, conv, activation = nn.ReLU, *args, **kwargs):\n",
        "    return nn.Sequential(OrderedDict({'conv': conv(in_channels, out_channels, \n",
        "                                                   kernel_size = 3, padding = 1, \n",
        "                                                   *args, **kwargs),\n",
        "                                      'bn': nn.BatchNorm3d(out_channels)}))\n",
        "    \n",
        "\n",
        "# ------------------------- CLASS BASIC BLOCK ----------------------------------\n",
        "class ResNetBasicBlock(ResNetResidualBlock):\n",
        "    expansion = 1\n",
        "    def __init__(self, in_channels, out_channels, *args, **kwargs):\n",
        "        super().__init__(in_channels, out_channels, *args, **kwargs)\n",
        "        self.blocks = nn.Sequential(\n",
        "            bn_conv(self.in_channels, self.out_channels, conv=self.conv, \n",
        "                     bias=False, stride=self.downsampling),\n",
        "            nn.ReLU(),\n",
        "            bn_conv(self.out_channels, self.expanded_channels, \n",
        "                     conv=self.conv, bias=False),\n",
        "        )\n",
        "\n",
        "\n",
        "# ------------------------- CLASS RESNET LAYER ---------------------------------\n",
        "class ResNetLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, block=ResNetBasicBlock, n=1, *args, **kwargs):\n",
        "        super().__init__()\n",
        "        # 'We perform downsampling directly by convolutional layers that have a stride of 2.'\n",
        "        downsampling = 2 if in_channels != out_channels else 1\n",
        "        \n",
        "        #first introduce block(... )\n",
        "        self.blocks = nn.Sequential(\n",
        "            block(in_channels , out_channels, *args, **kwargs, downsampling=downsampling),\n",
        "            # in the next the n-1 blocks are subsequently stacked (_ underscore means\n",
        "            # that the do_something will be executed the prescribed amount of times\n",
        "            *[block(out_channels * block.expansion, \n",
        "                    out_channels, downsampling=1, *args, **kwargs) for _ in range(n - 1)]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.blocks(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# ------------------------- CLASS RESNET ENCODER -------------------------------\n",
        "class ResNetEncoder(nn.Module): \n",
        "    def __init__(self, in_channels=3, blocks_sizes=[16, 32, 64], depths=[7,7,7], \n",
        "                 activation=nn.ReLU, block=ResNetBasicBlock, *args,**kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        self.blocks_sizes = blocks_sizes\n",
        "        \n",
        "        self.initconv = nn.Sequential(OrderedDict({\n",
        "            'conv'    : P4ConvZ2(in_channels, self.blocks_sizes[0], \n",
        "                        kernel_size=7, stride = 1, padding=3, bias=False),\n",
        "            'bn'      : nn.BatchNorm3d(self.blocks_sizes[0]),\n",
        "            'act'     : activation()})\n",
        "        )\n",
        "        \n",
        "        self.in_out_block_sizes = list(zip(blocks_sizes, blocks_sizes[1:]))\n",
        "        self.blocks = nn.ModuleList([ \n",
        "            ResNetLayer(blocks_sizes[0], blocks_sizes[0], n=depths[0], activation=activation, \n",
        "                        block=block,  *args, **kwargs),\n",
        "            *[ResNetLayer(in_channels * block.expansion, \n",
        "                          out_channels, n=n, activation=activation, \n",
        "                          block=block, *args, **kwargs) \n",
        "              for (in_channels, out_channels), n in zip(self.in_out_block_sizes, depths[1:])]       \n",
        "        ])\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.initconv(x)\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# ------------------------- CLASS RESNET DECODER -------------------------------\n",
        "class ResNetDecoder(nn.Module):\n",
        "    \"\"\"\n",
        "    This class represents the tail of ResNet. It performs a global pooling and maps the output to the\n",
        "    correct class by using a fully connected layer.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_features, n_classes, *args, **kwargs):\n",
        "        super().__init__()\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.decoder = nn.Linear(in_features, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1) #flatten\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# ------------------------------ CLASS RESNET ----------------------------------\n",
        "class ResNet(nn.Module):\n",
        "    '''\n",
        "    This class represents the full implementation of the residual network. This is\n",
        "    the connection of the encoder (initial convolution and residual stages) \n",
        "    followed by the decoder (fully connected network)\n",
        "    '''\n",
        "    def __init__(self, in_channels, n_classes, *args, **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = ResNetEncoder(in_channels, *args, **kwargs)\n",
        "        self.decoder = ResNetDecoder(self.encoder.blocks[-1].blocks[-1].expanded_channels*4, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        xs = x.size()\n",
        "        x = x.view(xs[0], xs[1]*xs[2], xs[3], xs[4])\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# ----------------------------- DEFINE RESNET44 --------------------------------\n",
        "def resnet44_P4(in_channels, n_classes):\n",
        "    return ResNet(in_channels, n_classes, block=ResNetBasicBlock, depths=[7, 7, 7])\n",
        "\n",
        "def arbitraryresnet(in_channels, n_classes):\n",
        "    return ResNet(in_channels, n_classes, block=ResNetBasicBlock, depths=[3, 3, 3])\n",
        "\n",
        "def test():\n",
        "    x = Variable(torch.randn(50,3,32,32))\n",
        "    net = resnet44_P4(3,10)\n",
        "    y = net(x)\n",
        "    print(y.size())\n",
        "\n",
        "test()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([50, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNqNZ_SoThUL",
        "colab_type": "text"
      },
      "source": [
        "#Summary of the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WojMUdYTdor",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#G-CNN group p4\n",
        "model_p4 = resnet44_P4(3, 10)\n",
        "summary(model_p4.cuda(), (3, 32, 32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmD6AzauTlVA",
        "colab_type": "text"
      },
      "source": [
        "#Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5BGxCkQTv6P",
        "colab_type": "code",
        "outputId": "a5492860-e0e0-4f32-f9dd-900ce37c7239",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Normalize a tensor image with mean and standard deviation. \n",
        "# Given mean: (M1,...,Mn) and std: (S1,..,Sn) for n channels, this transform will normalize each channel of the input torch.*Tensor i.e. input[channel] = (input[channel] - mean[channel]) / std[channel]\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Load training sets\n",
        "batch_size  = 32\n",
        "num_workers = 2\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=num_workers)\n",
        "\n",
        "# Load test sets\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=num_workers)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gprWKemUJVh",
        "colab_type": "text"
      },
      "source": [
        "#Training+Testing (code)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkqHQ5CEUM4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ------------------------- TRAINING THE NETWORK -------------------------------\n",
        "def train_network(net, train_loader, test_loader, device, title,\n",
        "                  lr = 0.05, momentum = 0.9, gamma = 0.1, \n",
        "                  n_epochs = 300, epoch_start = 0,\n",
        "                  criterion = nn.CrossEntropyLoss().cuda()):\n",
        "    \"\"\"\n",
        "    Training and evaluation of a connected network which should be written\n",
        "    in Pytorch fashion.\n",
        "    \"\"\"\n",
        "\n",
        "    print('training on', device)\n",
        "\n",
        "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "    #Create vectors with information on loss, training accuracy and test accuracy\n",
        "    loss_curve   = np.zeros((n_epochs))\n",
        "    train_curve  = np.zeros((n_epochs))\n",
        "    test_curve   = np.zeros((n_epochs))\n",
        "\n",
        "    #vector with epochs\n",
        "    epoch_vec = np.arange(epoch_start,n_epochs)\n",
        "\n",
        "    # ---------------------------- START TRAINING ------------------------------\n",
        "    for epoch in epoch_vec:\n",
        "\n",
        "        net.train()\n",
        "        n, start = 0, time.time()\n",
        "\n",
        "        train_l_sum   = torch.tensor([0.0], dtype=torch.float32, device=device)\n",
        "        train_acc_sum = torch.tensor([0.0], dtype=torch.float32, device=device)\n",
        "\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "            with torch.no_grad():\n",
        "                outputs = outputs.long()\n",
        "                train_l_sum += loss.float()\n",
        "                n += outputs.shape[0]\n",
        "\n",
        "        #update learning rate\n",
        "        if epoch <= 300:\n",
        "            if epoch % 50 == 49:\n",
        "                lr *= gamma\n",
        "                optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "                print('We got ourselves a change in learning rate:')\n",
        "                print('Epoch: '+ str(epoch))\n",
        "                print('Learning rate changed to: ' + str(lr))\n",
        "\n",
        "        # ------------------- START VALIDATION and SAVING ----------------------\n",
        "        loss_value = train_l_sum/n\n",
        "\n",
        "        stop1 = time.time()\n",
        "        train_acc  = evaluate_accuracy(train_loader, net, device)\n",
        "        stop2 = time.time()\n",
        "        test_acc   = evaluate_accuracy(test_loader, net, device)\n",
        "\n",
        "        loss_curve[epoch]  = loss_value\n",
        "        train_curve[epoch] = train_acc\n",
        "        test_curve[epoch]  = test_acc\n",
        "\n",
        "        curves = np.array([loss_curve, train_curve, test_curve])\n",
        "\n",
        "        #print updated scores\n",
        "        print('epoch %d [#]  |  loss %.4f [-]  |  train acc %.3f [-]  |  test acc %.3f [-]  |  time %.1f-%.1f-%.1f [s]'\\\n",
        "        % (epoch + 1, loss_value, train_acc, test_acc, stop1-start, stop2-stop1, time.time()-stop2))\n",
        "        \n",
        "        #save every 5 epochs\n",
        "        if epoch % 50 == 49:    # save every 10 epochs\n",
        "            #model\n",
        "            name_to_save = title + '__test=' + str(test_acc) + '%_train=' + str(train_acc) + '%_epoch=' + str(epoch+1)\n",
        "            directory = '/content/gdrive/My Drive/Deep Learning/Reproduction project/Saved Networks/Preliminary/'\n",
        "            path = '/content/gdrive/My Drive/Deep Learning/Reproduction project/Saved Networks/Preliminary/' + name_to_save + '.pth'\n",
        "            torch.save(model.state_dict(), path)\n",
        "            \n",
        "            #learning curves\n",
        "            path2 = directory + name_to_save + '_start:' + str(epoch_start)\n",
        "            np.save(path2, curves) \n",
        "      \n",
        "    print('Finished Training')\n",
        "    return loss_curve, train_curve, test_curve\n",
        "\n",
        "\n",
        "\n",
        "# ---------------------------------- VALIDATION --------------------------------\n",
        "def evaluate_accuracy(data_iter, net, device=torch.device('cpu')):\n",
        "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
        "    net.eval()  # Switch to evaluation mode for Dropout, BatchNorm etc layers.\n",
        "    acc_sum, n = torch.tensor([0], dtype=torch.float32, device=device), 0\n",
        "    for X, y in data_iter:\n",
        "        # Copy the data to device.\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        with torch.no_grad():\n",
        "            y = y.long()\n",
        "            acc_sum += torch.sum((torch.argmax(net(X), dim=1) == y))\n",
        "            n += y.shape[0]\n",
        "    return acc_sum.item()/n\n",
        "\n",
        "\n",
        "\n",
        "# --------------------------- WEIGHT INITIALIZATION ----------------------------\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "\n",
        "\n",
        "\n",
        "# ---------------------------- TRYING GPU of COLAB -----------------------------\n",
        "def try_gpu():\n",
        "    \"\"\"If GPU is available, return torch.device as cuda:0; else return torch.device as cpu.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda:0')\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "    return device"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsHnap6wUjQ6",
        "colab_type": "text"
      },
      "source": [
        "#Training+Testing(evaluation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf99-jnpUnvG",
        "colab_type": "code",
        "outputId": "67b09fef-e38d-40a7-8718-9731d1d70aad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        }
      },
      "source": [
        "device = try_gpu()\n",
        "\n",
        "model = resnet44_P4(3,10)\n",
        "model.cuda()\n",
        "\n",
        "#name_model = input('Name model?')\n",
        "#path_model = '/content/gdrive/My Drive/Deep Learning/Reproduction project/Saved Networks/Preliminary/' + name_model + '.pth'\n",
        "#model = resnet44_P4(3, 10)\n",
        "#result = model.load_state_dict(torch.load(path_model))\n",
        "#model.cuda()\n",
        "\n",
        "#pre-trained pytorch ResNet50\n",
        "#model = torch.hub.load('pytorch/vision:v0.5.0', 'resnet50', pretrained=True)\n",
        "\n",
        "epoch_start = 0\n",
        "lr = 0.05\n",
        "\n",
        "bs = input('What is the batch size:')\n",
        "title = 'ResNet44Groupy10_bs:' + bs +'_SGD_every50epochs'\n",
        "loss_curve, train_curve, test_curve = train_network(model, trainloader, testloader, device, title, n_epochs = 300, epoch_start = epoch_start, lr=lr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training on cuda:0\n",
            "epoch 1 [#]  |  loss 0.0690 [-]  |  train acc 0.286 [-]  |  test acc 0.288 [-]  |  time 148.8-53.1-10.8 [s]\n",
            "epoch 2 [#]  |  loss 0.0555 [-]  |  train acc 0.407 [-]  |  test acc 0.408 [-]  |  time 147.9-52.8-10.7 [s]\n",
            "epoch 3 [#]  |  loss 0.0481 [-]  |  train acc 0.489 [-]  |  test acc 0.487 [-]  |  time 149.3-54.2-10.7 [s]\n",
            "epoch 4 [#]  |  loss 0.0415 [-]  |  train acc 0.574 [-]  |  test acc 0.564 [-]  |  time 151.0-53.4-10.8 [s]\n",
            "epoch 5 [#]  |  loss 0.0338 [-]  |  train acc 0.681 [-]  |  test acc 0.665 [-]  |  time 147.8-52.6-10.8 [s]\n",
            "epoch 6 [#]  |  loss 0.0273 [-]  |  train acc 0.720 [-]  |  test acc 0.688 [-]  |  time 148.0-52.8-10.6 [s]\n",
            "epoch 7 [#]  |  loss 0.0227 [-]  |  train acc 0.783 [-]  |  test acc 0.743 [-]  |  time 147.2-52.4-10.5 [s]\n",
            "epoch 8 [#]  |  loss 0.0194 [-]  |  train acc 0.795 [-]  |  test acc 0.739 [-]  |  time 146.8-52.9-10.7 [s]\n",
            "epoch 9 [#]  |  loss 0.0163 [-]  |  train acc 0.850 [-]  |  test acc 0.771 [-]  |  time 148.1-53.1-10.8 [s]\n",
            "epoch 10 [#]  |  loss 0.0137 [-]  |  train acc 0.871 [-]  |  test acc 0.776 [-]  |  time 147.4-53.4-10.7 [s]\n",
            "epoch 11 [#]  |  loss 0.0111 [-]  |  train acc 0.914 [-]  |  test acc 0.795 [-]  |  time 149.0-53.1-10.8 [s]\n",
            "epoch 12 [#]  |  loss 0.0089 [-]  |  train acc 0.915 [-]  |  test acc 0.788 [-]  |  time 149.0-53.5-10.7 [s]\n",
            "epoch 13 [#]  |  loss 0.0071 [-]  |  train acc 0.935 [-]  |  test acc 0.783 [-]  |  time 149.2-53.7-10.9 [s]\n",
            "epoch 14 [#]  |  loss 0.0055 [-]  |  train acc 0.957 [-]  |  test acc 0.794 [-]  |  time 149.4-53.7-10.8 [s]\n",
            "epoch 15 [#]  |  loss 0.0042 [-]  |  train acc 0.961 [-]  |  test acc 0.799 [-]  |  time 149.4-53.3-10.7 [s]\n",
            "epoch 16 [#]  |  loss 0.0034 [-]  |  train acc 0.968 [-]  |  test acc 0.797 [-]  |  time 148.7-53.6-10.7 [s]\n",
            "epoch 17 [#]  |  loss 0.0026 [-]  |  train acc 0.982 [-]  |  test acc 0.798 [-]  |  time 149.1-53.2-10.7 [s]\n",
            "epoch 18 [#]  |  loss 0.0021 [-]  |  train acc 0.982 [-]  |  test acc 0.805 [-]  |  time 148.8-53.3-10.8 [s]\n",
            "epoch 19 [#]  |  loss 0.0018 [-]  |  train acc 0.963 [-]  |  test acc 0.780 [-]  |  time 148.6-53.2-10.8 [s]\n",
            "epoch 20 [#]  |  loss 0.0017 [-]  |  train acc 0.987 [-]  |  test acc 0.801 [-]  |  time 148.6-53.6-10.7 [s]\n",
            "epoch 21 [#]  |  loss 0.0012 [-]  |  train acc 0.994 [-]  |  test acc 0.816 [-]  |  time 148.8-53.7-10.9 [s]\n",
            "epoch 22 [#]  |  loss 0.0012 [-]  |  train acc 0.984 [-]  |  test acc 0.796 [-]  |  time 148.6-53.3-11.0 [s]\n",
            "epoch 23 [#]  |  loss 0.0010 [-]  |  train acc 0.992 [-]  |  test acc 0.804 [-]  |  time 148.7-53.3-10.9 [s]\n",
            "epoch 24 [#]  |  loss 0.0007 [-]  |  train acc 0.995 [-]  |  test acc 0.806 [-]  |  time 149.2-53.2-10.7 [s]\n",
            "epoch 25 [#]  |  loss 0.0007 [-]  |  train acc 0.995 [-]  |  test acc 0.811 [-]  |  time 149.0-53.8-10.9 [s]\n",
            "epoch 26 [#]  |  loss 0.0007 [-]  |  train acc 0.991 [-]  |  test acc 0.805 [-]  |  time 149.2-53.7-10.9 [s]\n",
            "epoch 27 [#]  |  loss 0.0008 [-]  |  train acc 0.994 [-]  |  test acc 0.811 [-]  |  time 149.0-53.8-10.9 [s]\n",
            "epoch 28 [#]  |  loss 0.0006 [-]  |  train acc 0.994 [-]  |  test acc 0.810 [-]  |  time 148.9-53.2-10.8 [s]\n",
            "epoch 29 [#]  |  loss 0.0005 [-]  |  train acc 0.998 [-]  |  test acc 0.822 [-]  |  time 149.1-53.6-10.7 [s]\n",
            "epoch 30 [#]  |  loss 0.0004 [-]  |  train acc 0.998 [-]  |  test acc 0.811 [-]  |  time 149.4-53.9-11.0 [s]\n",
            "epoch 31 [#]  |  loss 0.0003 [-]  |  train acc 0.999 [-]  |  test acc 0.821 [-]  |  time 149.7-53.9-10.9 [s]\n",
            "epoch 32 [#]  |  loss 0.0002 [-]  |  train acc 1.000 [-]  |  test acc 0.824 [-]  |  time 149.7-53.3-10.7 [s]\n",
            "epoch 33 [#]  |  loss 0.0001 [-]  |  train acc 1.000 [-]  |  test acc 0.819 [-]  |  time 149.4-53.4-10.8 [s]\n",
            "epoch 34 [#]  |  loss 0.0002 [-]  |  train acc 0.999 [-]  |  test acc 0.819 [-]  |  time 149.0-53.7-10.9 [s]\n",
            "epoch 35 [#]  |  loss 0.0002 [-]  |  train acc 0.998 [-]  |  test acc 0.810 [-]  |  time 148.9-53.6-10.8 [s]\n",
            "epoch 36 [#]  |  loss 0.0002 [-]  |  train acc 0.999 [-]  |  test acc 0.820 [-]  |  time 148.7-53.3-10.7 [s]\n",
            "epoch 37 [#]  |  loss 0.0002 [-]  |  train acc 1.000 [-]  |  test acc 0.820 [-]  |  time 149.0-53.4-10.9 [s]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-f0ace04d69a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'What is the batch size:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ResNet44Groupy10_bs:'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbs\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'_SGD_every50epochs'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mloss_curve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_curve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_curve\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-69ea0a3561b3>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(net, train_loader, test_loader, device, title, lr, momentum, gamma, n_epochs, epoch_start, criterion)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mstop1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mtrain_acc\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mevaluate_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mstop2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mtest_acc\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mevaluate_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-69ea0a3561b3>\u001b[0m in \u001b[0;36mevaluate_accuracy\u001b[0;34m(data_iter, net, device)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0macc_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0macc_sum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-57edc82de467>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-57edc82de467>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-57edc82de467>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-57edc82de467>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_apply_shortcut\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m#combination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gdrive/My Drive/Deep Learning/Reproduction project/GrouPy/groupy/gconv/pytorch_gconv/splitgconv2d.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mtw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrans_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         tw_shape = (self.out_channels * self.output_stabilizer_size,\n\u001b[1;32m     69\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_channels\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_stabilizer_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gdrive/My Drive/Deep Learning/Reproduction project/GrouPy/groupy/gconv/pytorch_gconv/splitgconv2d.py\u001b[0m in \u001b[0;36mtrans_filter\u001b[0;34m(w, inds)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrans_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0minds_reshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mw_indexed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds_reshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds_reshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds_reshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     w_indexed = w_indexed.view(w_indexed.size()[0], w_indexed.size()[1],\n\u001b[1;32m     19\u001b[0m                                     inds.shape[0], inds.shape[1], inds.shape[2], inds.shape[3])\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxxZAdPNUBfv",
        "colab_type": "text"
      },
      "source": [
        "#Loading Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fl2vV0pUDbZ",
        "colab_type": "code",
        "outputId": "91c217e5-96ce-481a-dee6-c192a523ccde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "#Loading model\n",
        "# BatchSize=16_NONpre__test=61.13%_train=66.414%_epoch=20\n",
        "device = try_gpu()\n",
        "load_model = input('Load model? [y/n]:  ')\n",
        "\n",
        "if load_model == 'y':\n",
        "    name_model = input('Name model?')\n",
        "    path_model = '/content/gdrive/My Drive/Deep Learning/Reproduction project/Saved Networks/Preliminary/' + name_model + '.pth'\n",
        "    model = ResNet(3, 10, block=ResNetBasicBlock, depths=[7, 7, 7])\n",
        "    result = model.load_state_dict(torch.load(path_model)) #check of alle weights zijn geladen\n",
        "    print('')\n",
        "    print('=== Weights loaded ===')\n",
        "    print('Missing keys:   ', result.missing_keys)\n",
        "    print('Unexpected keys:', result.unexpected_keys)\n",
        "\n",
        "model.cuda()\n",
        "\n",
        "#check accuracy\n",
        "\n",
        "check = input('Do you want to check accuracy? [y/n]:  ')\n",
        "if check == 'y':\n",
        "    print('')\n",
        "    print('Çheck training (first row) and test (second row) error:')\n",
        "    print(evaluate_accuracy(trainloader, model, device=device))\n",
        "    print(evaluate_accuracy(testloader, model, device=device))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load model? [y/n]y\n",
            "Name model?BatchSize=16_NONpre__test=61.13%_train=66.414%_epoch=20\n",
            "\n",
            "=== Weights loaded ===\n",
            "Missing keys:    []\n",
            "Unexpected keys: []\n",
            "\n",
            "Çheck training (first row) and test (second row) error:\n",
            "0.66414\n",
            "0.6113\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}